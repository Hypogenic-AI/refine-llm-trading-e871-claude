{"title": "FinMem: A Performance-Enhanced LLM Trading Agent With Layered Memory and Character Design", "year": 2023, "authors": "Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Jordan W. Suchow, Denghui Zhang, K. Khashanah", "url": "https://www.semanticscholar.org/paper/eb34bd715e3a7c68477ec0824ebb171b948b80c2", "relevance": 3, "abstract": "We introduce FinMem, a novel Large Language Models (LLM)-based agent framework for financial trading, designed to address the need for automated systems that can transform real-time data into executable decisions. FinMem comprises three core modules: Profile for customizing agent characteristics, Memory for hierarchical financial data assimilation, and Decision-making for converting insights into investment choices. The Memory module, which mimics human traders\u2019 cognitive structure, offers interpretability and real-time tuning while handling the critical timing of various information types. It employs a layered approach to process and prioritize data based on its timeliness and relevance, ensuring that the most recent and impactful information is given appropriate weight in decision-making. FinMem\u2019s adjustable cognitive span allows retention of critical information beyond human limits, enabling it to balance historical patterns with current market dynamics. This framework facilitates self-evolution of professional knowledge, agile reactions to investment cues, and continuous refinement of trading decisions in financial environments. When compared against advanced algorithmic agents using a large-scale real-world financial dataset, FinMem demonstrates superior performance across classic metrics like Cumulative Return and Sharpe ratio. Further tuning of the agent\u2019s perceptual span and character setting enhances its trading performance, positioning FinMem as a cutting-edge solution for automated trading.", "citations": 145}
{"title": "A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist", "year": 2024, "authors": "Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze Sun, Molei Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, Longtao Zheng, Xinrun Wang, Bo An", "url": "https://www.semanticscholar.org/paper/c86a70ff639707e647da3a429fe8e1e5c04415f5", "relevance": 3, "abstract": "Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantitative trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learning are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent's market intelligence module processes a diverse range of data-numerical, textual, and visual-to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorporates a diversified memory retrieval system, enhancing the agent's ability to learn from historical data and improve decision-making processes. The agent's emphasis on reasoning for actions fosters trust in its financial decisions. Moreover, FinAgent integrates established trading strategies and expert insights, ensuring that its trading approaches are both data-driven and rooted in sound financial principles. With comprehensive experiments on 6 financial datasets, including stocks and Crypto, FinAgent significantly outperforms 12 state-of-the-art baselines in terms of 6 financial metrics with over 36% average improvement on profit. Specifically, a 92.27% return (a 84.39% relative improvement) is achieved on one dataset. Notably, FinAgent is the first advanced multimodal foundation agent designed for financial trading tasks.", "citations": 122}
{"title": "FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making", "year": 2024, "authors": "Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W. Suchow, Rong Liu, Zhenyu Cui, Denghui Zhang, K. Subbalakshmi, Guojun Xiong, Yueru He, Jimin Huang, Dong Li, Qianqian Xie", "url": "https://www.semanticscholar.org/paper/0b41a6899c29a04e1217e6cc80a3d915ea18e2d8", "relevance": 3, "abstract": "Large language models (LLMs) have demonstrated notable potential in conducting complex tasks and are increasingly utilized in various financial applications. However, high-quality sequential financial investment decision-making remains challenging. These tasks require multiple interactions with a volatile environment for every decision, demanding sufficient intelligence to maximize returns and manage risks. Although LLMs have been used to develop agent systems that surpass human teams and yield impressive investment returns, opportunities to enhance multi-sourced information synthesis and optimize decision-making outcomes through timely experience refinement remain unexplored. Here, we introduce the FinCon, an LLM-based multi-agent framework with CONceptual verbal reinforcement tailored for diverse FINancial tasks. Inspired by effective real-world investment firm organizational structures, FinCon utilizes a manager-analyst communication hierarchy. This structure allows for synchronized cross-functional agent collaboration towards unified goals through natural language interactions and equips each agent with greater memory capacity than humans. Additionally, a risk-control component in FinCon enhances decision quality by episodically initiating a self-critiquing mechanism to update systematic investment beliefs. The conceptualized beliefs serve as verbal reinforcement for the future agent's behavior and can be selectively propagated to the appropriate node that requires knowledge updates. This feature significantly improves performance while reducing unnecessary peer-to-peer communication costs. Moreover, FinCon demonstrates strong generalization capabilities in various financial tasks, including single stock trading and portfolio management.", "citations": 95}
{"title": "TradingAgents: Multi-Agents LLM Financial Trading Framework", "year": 2024, "authors": "Yijia Xiao, Edward Sun, Di Luo, Wei Wang", "url": "https://www.semanticscholar.org/paper/e3dd4964c07c914a0ccca2e2f3ed6410f8a86a6a", "relevance": 3, "abstract": "Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, the multi-agent systems' potential to replicate real-world trading firms' collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at https://github.com/TauricResearch/TradingAgents.", "citations": 90}
{"title": "TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance", "year": 2023, "authors": "Yang Li, Yangyang Yu, Haohang Li, Z. Chen, K. Khashanah", "url": "https://api.semanticscholar.org/CorpusId:261582775", "relevance": 3, "abstract": "Large Language Models (LLMs), prominently highlighted by the recent evolution in the Generative Pre-trained Transformers (GPT) series, have displayed significant prowess across various domains, such as aiding in healthcare diagnostics and curating analytical business reports. The efficacy of GPTs lies in their ability to decode human instructions, achieved through comprehensively processing historical inputs as an entirety within their memory system. Yet, the memory processing of GPTs does not precisely emulate the hierarchical nature of human memory. This can result in LLMs struggling to prioritize immediate and critical tasks efficiently. To bridge this gap, we introduce an innovative LLM multi-agent framework endowed with layered memories. We assert that this framework is well-suited for stock and fund trading, where the extraction of highly relevant insights from hierarchical financial data is imperative to inform trading decisions. Within this framework, one agent organizes memory into three distinct layers, each governed by a custom decay mechanism, aligning more closely with human cognitive processes. Agents can also engage in inter-agent debate. In financial trading contexts, LLMs serve as the decision core for trading agents, leveraging their layered memory system to integrate multi-source historical actions and market insights. This equips them to navigate financial changes, formulate strategies, and debate with peer agents about investment decisions. Another standout feature of our approach is to equip agents with individualized trading traits, enhancing memory diversity and decision robustness. These sophisticated designs boost the system's responsiveness to historical trades and real-time market signals, ensuring superior automated trading accuracy.", "citations": 85}
{"title": "Large Language Model Agent in Financial Trading: A Survey", "year": 2024, "authors": "Han Ding, Yinheng Li, Junhao Wang, Hang Chen", "url": "https://www.semanticscholar.org/paper/6abfd5d2f175760f596ea56ee62b856bbb5beb9b", "relevance": 3, "abstract": "Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude. With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders. In this survey, we provide a comprehensive review of the current research on using LLMs as agents in financial trading. We summarize the common architecture used in the agent, the data inputs, and the performance of LLM trading agents in backtesting as well as the challenges presented in these research. This survey aims to provide insights into the current state of LLM-based financial trading agents and outline future research directions in this field.", "citations": 51}
{"title": "INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent", "year": 2024, "authors": "Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, K. Subbalakshmi, Guojun Xiong, Jimin Huang, Lingfei Qian, Xueqing Peng, Qianqian Xie, Jordan W. Suchow", "url": "https://www.semanticscholar.org/paper/74e898dbf4a82980d600828f6ffcb6cd1c4d1522", "relevance": 3, "abstract": "Recent advancements have underscored the potential of large language model (LLM)-based agents in financial decision-making. Despite this progress, the field currently encounters two main challenges: (1) the lack of a comprehensive LLM agent framework adaptable to a variety of financial tasks, and (2) the absence of standardized benchmarks and consistent datasets for assessing agent performance. To tackle these issues, we introduce \\textsc{InvestorBench}, the first benchmark specifically designed for evaluating LLM-based agents in diverse financial decision-making contexts. InvestorBench enhances the versatility of LLM-enabled agents by providing a comprehensive suite of tasks applicable to different financial products, including single equities like stocks, cryptocurrencies and exchange-traded funds (ETFs). Additionally, we assess the reasoning and decision-making capabilities of our agent framework using thirteen different LLMs as backbone models, across various market environments and tasks. Furthermore, we have curated a diverse collection of open-source, multi-modal datasets and developed a comprehensive suite of environments for financial decision-making. This establishes a highly accessible platform for evaluating financial agents' performance across various scenarios.", "citations": 26}
{"title": "Simulating Financial Market via Large Language Model based Agents", "year": 2024, "authors": "Shen Gao, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, Shuo Shang", "url": "https://www.semanticscholar.org/paper/7150e17eac46cfdfc303ceef882d115e0232de46", "relevance": 3, "abstract": "Most economic theories typically assume that financial market participants are fully rational individuals and use mathematical models to simulate human behavior in financial markets. However, human behavior is often not entirely rational and is challenging to predict accurately with mathematical models. In this paper, we propose \\textbf{A}gent-based \\textbf{S}imulated \\textbf{F}inancial \\textbf{M}arket (ASFM), which first constructs a simulated stock market with a real order matching system. Then, we propose a large language model based agent as the stock trader, which contains the profile, observation, and tool-learning based action module. The trading agent can comprehensively understand current market dynamics and financial policy information, and make decisions that align with their trading strategy. In the experiments, we first verify that the reactions of our ASFM are consistent with the real stock market in two controllable scenarios. In addition, we also conduct experiments in two popular economics research directions, and we find that conclusions drawn in our \\model align with the preliminary findings in economics research. Based on these observations, we believe our proposed ASFM provides a new paradigm for economic research.", "citations": 26}
{"title": "When AI Meets Finance (StockAgent): Large Language Model-based Stock Trading in Simulated Real-world Environments", "year": 2024, "authors": "Chong Zhang, Xinyi Liu, Mingyu Jin, Zhongmou Zhang, Lingyao Li, Zhengting Wang, Wenyue Hua, Dong Shu, Suiyuan Zhu, Xiaobo Jin, Sujian Li, Mengnan Du, Yongfeng Zhang", "url": "https://api.semanticscholar.org/CorpusId:271533952", "relevance": 3, "abstract": "Can AI Agents simulate real-world trading environments to investigate the impact of external factors on stock trading activities (e.g., macroeconomics, policy changes, company fundamentals, and global events)? These factors, which frequently influence trading behaviors, are critical elements in the quest for maximizing investors' profits. Our work attempts to solve this problem through large language model based agents. We have developed a multi-agent AI system called StockAgent, driven by LLMs, designed to simulate investors' trading behaviors in response to the real stock market. The StockAgent allows users to evaluate the impact of different external factors on investor trading and to analyze trading behavior and profitability effects. Additionally, StockAgent avoids the test set leakage issue present in existing trading simulation systems based on AI Agents. Specifically, it prevents the model from leveraging prior knowledge it may have acquired related to the test data. We evaluate different LLMs under the framework of StockAgent in a stock trading environment that closely resembles real-world conditions. The experimental results demonstrate the impact of key external factors on stock market trading, including trading behavior and stock price fluctuation rules. This research explores the study of agents' free trading gaps in the context of no prior knowledge related to market data. The patterns identified through StockAgent simulations provide valuable insights for LLM-based investment advice and stock recommendation. The code is available at https://github.com/MingyuJ666/Stockagent.", "citations": 22}
{"title": "FinVision: A Multi-Agent Framework for Stock Market Prediction", "year": 2024, "authors": "Sorouralsadat Fatemi, Yuheng Hu", "url": "https://www.semanticscholar.org/paper/24372808f30e2d94b32c41b79e1cdc3b1540d984", "relevance": 3, "abstract": "Financial trading has been a challenging task, as it requires the integration of vast amounts of data from various modalities. Traditional deep learning and reinforcement learning methods require large training data and often involve encoding various data types into numerical formats for model input, which limits the explainability of model behavior. Recently, LLM-based agents have demonstrated remarkable advancements in handling multi-modal data, enabling them to execute complex, multi-step decision-making tasks while providing insights into their thought processes. This research introduces a multi-modal multi-agent system designed specifically for financial trading tasks. Our framework employs a team of specialized LLM-based agents, each adept at processing and interpreting various forms of financial data, such as textual news reports, candlestick charts, and trading signal charts. A key feature of our approach is the integration of a reflection module, which conducts analyses of historical trading signals and their outcomes. This reflective process is instrumental in enhancing the decision-making capabilities of the system for future trading scenarios. Furthermore, the ablation studies indicate that the visual reflection module plays a crucial role in enhancing the decision-making capabilities of our framework.", "citations": 19}
{"title": "Automate Strategy Finding with LLM in Quant investment", "year": 2024, "authors": "Zhizhuo Kou, Holam Yu, Jingshu Peng, Lei Chen", "url": "https://www.semanticscholar.org/paper/1b31930e05ba75daf9dafb409242b53af663db66", "relevance": 3, "abstract": "We present a novel three-stage framework leveraging Large Language Models (LLMs) within a risk-aware multi-agent system for automate strategy finding in quantitative finance. Our approach addresses the brittleness of traditional deep learning models in financial applications by: employing prompt-engineered LLMs to generate executable alpha factor candidates across diverse financial data, implementing multimodal agent-based evaluation that filters factors based on market status, predictive quality while maintaining category balance, and deploying dynamic weight optimization that adapts to market conditions. Experimental results demonstrate the robust performance of the strategy in Chinese&US market regimes compared to established benchmarks. Our work extends LLMs capabilities to quantitative trading, providing a scalable architecture for financial signal extraction and portfolio construction. The overall framework significantly outperforms all benchmarks with 53.17% cumulative return on SSE50 (Jan 2023 to Jan 2024), demonstrating superior risk-adjusted performance and downside protection on the market.", "citations": 22}
{"title": "FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading", "year": 2025, "authors": "Guojun Xiong, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang Yu, Xueqing Peng, Mingquan Lin, Kaleb E Smith, Xiao-Yang Liu, Jimin Huang, Sophia Ananiadou, Qianqian Xie", "url": "https://www.semanticscholar.org/paper/c6e145e7e9e6a6e82e898d6e96997461cd5ec608", "relevance": 3, "abstract": "Large language models (LLMs) fine-tuned on multimodal financial data have demonstrated impressive reasoning capabilities in various financial tasks. However, they often struggle with multi-step, goal-oriented scenarios in interactive financial markets, such as trading, where complex agentic approaches are required to improve decision-making. To address this, we propose \\textsc{FLAG-Trader}, a unified architecture integrating linguistic processing (via LLMs) with gradient-driven reinforcement learning (RL) policy optimization, in which a partially fine-tuned LLM acts as the policy network, leveraging pre-trained knowledge while adapting to the financial domain through parameter-efficient fine-tuning. Through policy gradient optimization driven by trading rewards, our framework not only enhances LLM performance in trading but also improves results on other financial-domain tasks. We present extensive empirical evidence to validate these enhancements.", "citations": 17}
{"title": "From Deep Learning to LLMs: A survey of AI in Quantitative Investment", "year": 2025, "authors": "Bokai Cao, Sai Wang, Xinyi Lin, Xiaojun Wu, Haohan Zhang, Lionel M. Ni, Jian Guo", "url": "https://www.semanticscholar.org/paper/a357eb33b3694f1e8316690b2a47c5e9f62203ce", "relevance": 3, "abstract": "Quantitative investment (quant) is an emerging, technology-driven approach in asset management, increasingy shaped by advancements in artificial intelligence. Recent advances in deep learning and large language models (LLMs) for quant finance have improved predictive modeling and enabled agent-based automation, suggesting a potential paradigm shift in this field. In this survey, taking alpha strategy as a representative example, we explore how AI contributes to the quantitative investment pipeline. We first examine the early stage of quant research, centered on human-crafted features and traditional statistical models with an established alpha pipeline. We then discuss the rise of deep learning, which enabled scalable modeling across the entire pipeline from data processing to order execution. Building on this, we highlight the emerging role of LLMs in extending AI beyond prediction, empowering autonomous agents to process unstructured data, generate alphas, and support self-iterative workflows.", "citations": 11}
{"title": "Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations", "year": 2025, "authors": "Alejandro Lopez-Lira", "url": "https://www.semanticscholar.org/paper/e97ab13fb2a142c61a2c1192d097e98e6662a7ac", "relevance": 3, "abstract": "This paper presents a realistic simulated stock market where large language models (LLMs) act as heterogeneous competing trading agents. The open-source framework incorporates a persistent order book with market and limit orders, partial fills, dividends, and equilibrium clearing alongside agents with varied strategies, information sets, and endowments. Agents submit standardized decisions using structured outputs and function calls while expressing their reasoning in natural language. Three findings emerge: First, LLMs demonstrate consistent strategy adherence and can function as value investors, momentum traders, or market makers per their instructions. Second, market dynamics exhibit features of real financial markets, including price discovery, bubbles, underreaction, and strategic liquidity provision. Third, the framework enables analysis of LLMs' responses to varying market conditions, similar to partial dependence plots in machine-learning interpretability. The framework allows simulating financial theories without closed-form solutions, creating experimental designs that would be costly with human participants, and establishing how prompts can generate correlated behaviors affecting market stability.", "citations": 8}
{"title": "Large Language Models in equity markets: applications, techniques, and insights", "year": 2025, "authors": "Aakanksha Jadhav, Vishal Mirza", "url": "https://www.semanticscholar.org/paper/b1553a62bd4fbf76ad6a41f05a1a4a5a13e862ad", "relevance": 3, "abstract": "Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector.", "citations": 10}
{"title": "StockBench: Can LLM Agents Trade Stocks Profitably In Real-world Markets?", "year": 2025, "authors": "Yanxu Chen, Zijun Yao, Yantao Liu, Jin Ye, Jianing Yu, Lei Hou, Juanzi Li", "url": "https://www.semanticscholar.org/paper/30a0ed9ea36d6928b94a7ffdc9db2ebc1c88f75a", "relevance": 3, "abstract": "Large language models (LLMs) have recently demonstrated strong capabilities as autonomous agents, showing promise in reasoning, tool use, and sequential decision-making. While prior benchmarks have evaluated LLM agents in domains such as software engineering and scientific discovery, the finance domain remains underexplored, despite its direct relevance to economic value and high-stakes decision-making. Existing financial benchmarks primarily test static knowledge through question answering, but they fall short of capturing the dynamic and iterative nature of trading. To address this gap, we introduce StockBench, a contamination-free benchmark designed to evaluate LLM agents in realistic, multi-month stock trading environments. Agents receive daily market signals -- including prices, fundamentals, and news -- and must make sequential buy, sell, or hold decisions. Performance is assessed using financial metrics such as cumulative return, maximum drawdown, and the Sortino ratio. Our evaluation of state-of-the-art proprietary (e.g., GPT-5, Claude-4) and open-weight (e.g., Qwen3, Kimi-K2, GLM-4.5) models shows that while most LLM agents struggle to outperform the simple buy-and-hold baseline, several models demonstrate the potential to deliver higher returns and manage risk more effectively. These findings highlight both the challenges and opportunities in developing LLM-powered financial agents, showing that excelling at static financial knowledge tasks does not necessarily translate into successful trading strategies. We release StockBench as an open-source resource to support reproducibility and advance future research in this domain.", "citations": 6}
{"title": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "year": 2025, "authors": "Sedigheh Mahdavi, Jiating Chen, Pradeep Kumar Joshi, L. H. Guativa, Upmanyu Singh", "url": "https://www.semanticscholar.org/paper/6e8331657256fdc8f83dd534fcdbf12dfa375359", "relevance": 3, "abstract": "Large Language Models (LLMs) have been employed in financial decision making, enhancing analytical capabilities for investment strategies. Traditional investment strategies often utilize quantitative models, fundamental analysis, and technical indicators. However, LLMs have introduced new capabilities to process and analyze large volumes of structured and unstructured data, extract meaningful insights, and enhance decision-making in real-time. This survey provides a structured overview of recent research on LLMs within the financial domain, categorizing research contributions into four main frameworks: LLM-based Frameworks and Pipelines, Hybrid Integration Methods, Fine-Tuning and Adaptation Approaches, and Agent-Based Architectures. This study provides a structured review of recent LLMs research on applications in stock selection, risk assessment, sentiment analysis, trading, and financial forecasting. By reviewing the existing literature, this study highlights the capabilities, challenges, and potential directions of LLMs in financial markets.", "citations": 5}
{"title": "When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents", "year": 2025, "authors": "Lingfei Qian, Xueqing Peng, Yan Wang, V. Zhang, Huan He, Hanley Smith, Yi Han, Yueru He, Haohang Li, Yupeng Cao, Yangyang Yu, Alejandro Lopez-Lira, Peng Lu, Jian-yun Nie, Guojun Xiong, Jimin Huang, Sophia Ananiadou", "url": "https://www.semanticscholar.org/paper/efbbb0b34d1f07b1c2c3cc2eda3ddec0d9136180", "relevance": 3, "abstract": "Although Large Language Model (LLM)-based agents are increasingly used in financial trading, it remains unclear whether they can reason and adapt in live markets, as most studies test models instead of agents, cover limited periods and assets, and rely on unverified data. To address these gaps, we introduce Agent Market Arena (AMA), the first lifelong, real-time benchmark for evaluating LLM-based trading agents across multiple markets. AMA integrates verified trading data, expert-checked news, and diverse agent architectures within a unified trading framework, enabling fair and continuous comparison under real conditions. It implements four agents, including InvestorAgent as a single-agent baseline, TradeAgent and HedgeFundAgent with different risk styles, and DeepFundAgent with memory-based reasoning, and evaluates them across GPT-4o, GPT-4.1, Claude-3.5-haiku, Claude-sonnet-4, and Gemini-2.0-flash. Live experiments on both cryptocurrency and stock markets demonstrate that agent frameworks display markedly distinct behavioral patterns, spanning from aggressive risk-taking to conservative decision-making, whereas model backbones contribute less to outcome variation. AMA thus establishes a foundation for rigorous, reproducible, and continuously evolving evaluation of financial reasoning and trading intelligence in LLM-based agents.", "citations": 1}
{"title": "To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions", "year": 2025, "authors": "Dimitrios Emmanoulopoulos, Ollie Olby, Justin Lyon, Namid R Stillman", "url": "https://api.semanticscholar.org/CorpusId:280281425", "relevance": 3, "abstract": "Large language models (LLMs) are increasingly deployed in agentic frameworks, in which prompts trigger complex tool-based analysis in pursuit of a goal. While these frameworks have shown promise across multiple domains including in finance, they typically lack a principled model-building step, relying instead on sentiment- or trend-based analysis. We address this gap by developing an agentic system that uses LLMs to iteratively discover stochastic differential equations for financial time series. These models generate risk metrics which inform daily trading decisions. We evaluate our system in both traditional backtests and using a market simulator, which introduces synthetic but causally plausible price paths and news events. We find that model-informed trading strategies outperform standard LLM-based agents, improving Sharpe ratios across multiple equities. Our results show that combining LLMs with agentic model discovery enhances market risk estimation and enables more profitable trading decisions.", "citations": 1}
{"title": "ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism", "year": 2025, "authors": "Li Zhao, Rui Sun, Zuoyou Jiang, Bo Yang, Yuxiao Bai, Mengting Chen, Xinyang Wang, Jing Li, Zuo Bai", "url": "https://www.semanticscholar.org/paper/697f3151a670b79c7e30cf359eb0686837cd1082", "relevance": 3, "abstract": "In financial trading, large language model (LLM)-based agents demonstrate significant potential. However, the high sensitivity to market noise undermines the performance of LLM-based trading systems. To address this limitation, we propose a novel multi-agent system featuring an internal competitive mechanism inspired by modern corporate management structures. The system consists of two specialized teams: (1) Data Team - responsible for processing and condensing massive market data into diversified text factors, ensuring they fit the model's constrained context. (2) Research Team - tasked with making parallelized multipath trading decisions based on deep research methods. The core innovation lies in implementing a real-time evaluation and ranking mechanism within each team, driven by authentic market feedback. Each agent's performance undergoes continuous scoring and ranking, with only outputs from top-performing agents being adopted. The design enables the system to adaptively adjust to dynamic environment, enhances robustness against market noise and ultimately delivers superior trading performance. Experimental results demonstrate that our proposed system significantly outperforms prevailing multi-agent systems and traditional quantitative investment methods across diverse evaluation metrics. ContestTrade is open-sourced on GitHub at https://github.com/FinStep-AI/ContestTrade.", "citations": 3}
{"title": "LiveTradeBench: Seeking Real-World Alpha with Large Language Models", "year": 2025, "authors": "Haofei Yu, Fenghai Li, Jiaxuan You", "url": "https://www.semanticscholar.org/paper/9b8944c299cd7ce32db8bf187b96b508bede49d1", "relevance": 3, "abstract": "Large language models (LLMs) achieve strong performance across benchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but these tests occur in static settings, lacking real dynamics and uncertainty. Consequently, they evaluate isolated reasoning or problem-solving rather than decision-making under uncertainty. To address this, we introduce LiveTradeBench, a live trading environment for evaluating LLM agents in realistic and evolving markets. LiveTradeBench follows three design principles: (i) Live data streaming of market prices and news, eliminating dependence on offline backtesting and preventing information leakage while capturing real-time uncertainty; (ii) a portfolio-management abstraction that extends control from single-asset actions to multi-asset allocation, integrating risk management and cross-asset reasoning; and (iii) multi-market evaluation across structurally distinct environments--U.S. stocks and Polymarket prediction markets--differing in volatility, liquidity, and information flow. At each step, an agent observes prices, news, and its portfolio, then outputs percentage allocations that balance risk and return. Using LiveTradeBench, we run 50-day live evaluations of 21 LLMs across families. Results show that (1) high LMArena scores do not imply superior trading outcomes; (2) models display distinct portfolio styles reflecting risk appetite and reasoning dynamics; and (3) some LLMs effectively leverage live signals to adapt decisions. These findings expose a gap between static evaluation and real-world competence, motivating benchmarks that test sequential decision making and consistency under live uncertainty.", "citations": 3}
{"title": "FinWorld: An All-in-One Open-Source Platform for End-to-End Financial AI Research and Deployment", "year": 2025, "authors": "Wentao Zhang, Yilei Zhao, Chuqiao Zong, Xinrun Wang, Bo An", "url": "https://api.semanticscholar.org/CorpusId:280421572", "relevance": 3, "abstract": "Financial AI holds great promise for transforming modern finance, with the potential to support a wide range of tasks such as market forecasting, portfolio management, quantitative trading, and automated analysis. However, existing platforms remain limited in task coverage, lack robust multimodal data integration, and offer insufficient support for the training and deployment of large language models (LLMs). In response to these limitations, we present FinWorld, an all-in-one open-source platform that provides end-to-end support for the entire financial AI workflow, from data acquisition to experimentation and deployment. FinWorld distinguishes itself through native integration of heterogeneous financial data, unified support for diverse AI paradigms, and advanced agent automation, enabling seamless development and deployment. Leveraging data from 2 representative markets, 4 stock pools, and over 800 million financial data points, we conduct comprehensive experiments on 4 key financial AI tasks. These experiments systematically evaluate deep learning and reinforcement learning algorithms, with particular emphasis on RL-based finetuning for LLMs and LLM Agents. The empirical results demonstrate that FinWorld significantly enhances reproducibility, supports transparent benchmarking, and streamlines deployment, thereby providing a strong foundation for future research and real-world applications. Code is available at Github~\\footnote{https://github.com/DVampire/FinWorld}.", "citations": 2}
{"title": "AI-Trader: Benchmarking Autonomous Agents in Real-Time Financial Markets", "year": 2025, "authors": "Tianyu Fan, Yuhao Yang, Ya Jiang, Yifei Zhang, Yuxuan Chen, Chao Huang", "url": "https://www.semanticscholar.org/paper/2f233fdd043f3a1c42e50713286041a5cdbeeb2f", "relevance": 3, "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential as autonomous agents, approaching human-expert performance through advanced reasoning and tool orchestration. However, decision-making in fully dynamic and live environments remains highly challenging, requiring real-time information integration and adaptive responses. While existing efforts have explored live evaluation mechanisms in structured tasks, a critical gap remains in systematic benchmarking for real-world applications, particularly in finance where stringent requirements exist for live strategic responsiveness. To address this gap, we introduce AI-Trader, the first fully-automated, live, and data-uncontaminated evaluation benchmark for LLM agents in financial decision-making. AI-Trader spans three major financial markets: U.S. stocks, A-shares, and cryptocurrencies, with multiple trading granularities to simulate live financial environments. Our benchmark implements a revolutionary fully autonomous minimal information paradigm where agents receive only essential context and must independently search, verify, and synthesize live market information without human intervention. We evaluate six mainstream LLMs across three markets and multiple trading frequencies. Our analysis reveals striking findings: general intelligence does not automatically translate to effective trading capability, with most agents exhibiting poor returns and weak risk management. We demonstrate that risk control capability determines cross-market robustness, and that AI trading strategies achieve excess returns more readily in highly liquid markets than policy-driven environments. These findings expose critical limitations in current autonomous agents and provide clear directions for future improvements. The code and evaluation data are open-sourced to foster community research: https://github.com/HKUDS/AI-Trader.", "citations": 2}
{"title": "TradingGroup: A Multi-Agent Trading System with Self-Reflection and Data-Synthesis", "year": 2025, "authors": "Feng Tian, Flora D. Salim, Hao Xue", "url": "https://www.semanticscholar.org/paper/0b49f889237966c002165ae9af2be864187a02d2", "relevance": 3, "abstract": "Recent advancements in large language models (LLMs) have enabled powerful agent-based applications in finance, particularly for sentiment analysis, financial report comprehension, and stock forecasting. However, existing systems often lack inter-agent coordination, structured self-reflection, and access to high-quality, domain-specific post-training data such as data from trading activities including both market conditions and agent decisions. These data are crucial for agents to understand the market dynamics, improve the quality of decision-making and promote effective coordination. We introduce TradingGroup, a multi-agent trading system designed to address these limitations through a self-reflective architecture and an end-to-end data-synthesis pipeline. TradingGroup consists of specialized agents for news sentiment analysis, financial report interpretation, stock trend forecasting, trading style adaptation, and a trading decision making agent that merges all signals and style preferences to produce buy, sell or hold decisions. Specifically, we design self-reflection mechanisms for the stock forecasting, style, and decision-making agents to distill past successes and failures for similar reasoning in analogous future scenarios and a dynamic risk-management model to offer configurable dynamic stop-loss and take-profit mechanisms. In addition, TradingGroup embeds an automated data-synthesis and annotation pipeline that generates high-quality post-training data for further improving the agent performance through post-training. Our backtesting experiments across five real-world stock datasets demonstrate TradingGroup's superior performance over rule-based, machine learning, reinforcement learning, and existing LLM-based trading strategies.", "citations": 2}
{"title": "Integrating Traditional Technical Analysis with AI: A Multi-Agent LLM-Based Approach to Stock Market Forecasting", "year": 2025, "authors": "Micha\u0142 Wawer, Jaros\u0142aw A. Chudziak", "url": "https://www.semanticscholar.org/paper/d96ce80541b552fd703291594939bc9d624bb7ae", "relevance": 3, "abstract": "Traditional technical analysis methods face limitations in accurately predicting trends in today's complex financial markets. This paper introduces ElliottAgents, an multi-agent system that integrates the Elliott Wave Principle with AI for stock market forecasting. The inherent complexity of financial markets, characterized by non-linear dynamics, noise, and susceptibility to unpredictable external factors, poses significant challenges for accurate prediction. To address these challenges, the system employs LLMs to enhance natural language understanding and decision-making capabilities within a multi-agent framework. By leveraging technologies such as Retrieval-Augmented Generation (RAG) and Deep Reinforcement Learning (DRL), ElliottAgents performs continuous, multi-faceted analysis of market data to identify wave patterns and predict future price movements. The research explores the system's ability to process historical stock data, recognize Elliott wave patterns, and generate actionable insights for traders. Experimental results, conducted on historical data from major U.S. companies, validate the system's effectiveness in pattern recognition and trend forecasting across various time frames. This paper contributes to the field of AI-driven financial analysis by demonstrating how traditional technical analysis methods can be effectively combined with modern AI approaches to create more reliable and interpretable market prediction systems.", "citations": 3}
{"title": "Agent Trading Arena: A Study on Numerical Understanding in LLM-Based Agents", "year": 2025, "authors": "Tianmi Ma, Jiawei Du, Wenxin Huang, Wenjie Wang, Liang Xie, Xian Zhong, Joey Tianyi Zhou", "url": "https://www.semanticscholar.org/paper/95f225d1e545977115c535bcd696025a043e590e", "relevance": 3, "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in natural language tasks, yet their performance in dynamic, real-world financial environments remains underexplored. Existing approaches are limited to historical backtesting, where trading actions cannot influence market prices and agents train only on static data. To address this limitation, we present the Agent Trading Arena, a virtual zero-sum stock market in which LLM-based agents engage in competitive multi-agent trading and directly impact price dynamics. By simulating realistic bid-ask interactions, our platform enables training in scenarios that closely mirror live markets, thereby narrowing the gap between training and evaluation. Experiments reveal that LLMs struggle with numerical reasoning when given plain-text data, often overfitting to local patterns and recent values. In contrast, chart-based visualizations significantly enhance both numerical reasoning and trading performance. Furthermore, incorporating a reflection module yields additional improvements, especially with visual inputs. Evaluations on NASDAQ and CSI datasets demonstrate the superiority of our method, particularly under high volatility. All code and data are available at https://github.com/wekjsdvnm/Agent-Trading-Arena.", "citations": 3}
{"title": "Agent-Based Simulation of a Financial Market with Large Language Models", "year": 2025, "authors": "Ryuji Hashimoto, Takehiro Takayanagi, Masahiro Suzuki, Kiyoshi Izumi", "url": "https://api.semanticscholar.org/CorpusId:282064483", "relevance": 3, "abstract": "In real-world stock markets, certain chart patterns -- such as price declines near historical highs -- cannot be fully explained by fundamentals alone. These phenomena suggest the presence of path dependence in price formation, where investor decisions are influenced not only by current market conditions but also by the trajectory of prices leading up to the present. Path dependence has drawn attention in behavioral finance as a key mechanism behind such anomalies. One plausible driver of path dependence is human loss aversion, anchored to individual reference points like purchase prices or past peaks, which vary with personal context. However, capturing such subtle behavioral tendencies in traditional agent-based market simulations has remained a challenge. We propose the Fundamental-Chartist-LLM-Agent (FCLAgent), which uses large language models (LLMs) to emulate human-like trading decisions. In this framework, (1) buy/sell decisions are made by LLMs based on individual situations, while (2) order price and volume follow standard rule-based methods. Simulations show that FCLAgents reproduce path-dependent patterns that conventional agents fail to capture. Furthermore, an analysis of FCLAgents'behavior reveals that the reference points guiding loss aversion vary with market trajectories, highlighting the potential of LLM-based agents to model nuanced investor behavior.", "citations": 0}
{"title": "QuantAgents: Towards Multi-agent Financial System via Simulated Trading", "year": 2025, "authors": "Xiangyu Li, Yawen Zeng, Xiaofen Xing, Jin Xu, Xiangmin Xu", "url": "https://api.semanticscholar.org/CorpusId:281843943", "relevance": 3, "abstract": "In this paper, our objective is to develop a multi-agent financial system that incorporates simulated trading, a technique extensively utilized by financial professionals. While current LLM-based agent models demonstrate competitive performance, they still exhibit significant deviations from real-world fund companies. A critical distinction lies in the agents'reliance on ``post-reflection'', particularly in response to adverse outcomes, but lack a distinctly human capability: long-term prediction of future trends. Therefore, we introduce QuantAgents, a multi-agent system integrating simulated trading, to comprehensively evaluate various investment strategies and market scenarios without assuming actual risks. Specifically, QuantAgents comprises four agents: a simulated trading analyst, a risk control analyst, a market news analyst, and a manager, who collaborate through several meetings. Moreover, our system incentivizes agents to receive feedback on two fronts: performance in real-world markets and predictive accuracy in simulated trading. Extensive experiments demonstrate that our framework excels across all metrics, yielding an overall return of nearly 300% over the three years (https://quantagents.github.io/).", "citations": 3}
{"title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "year": 2025, "authors": "Taian Guo, Haiyang Shen, Jinsheng Huang, Zhengyan Mao, Junyu Luo, Zhuorui Chen, Xuhui Liu, Bingyu Xia, Luchen Liu, Yun Ma, Ming Zhang", "url": "https://www.semanticscholar.org/paper/82804209a776b25f019c6a6082917eca98c0d5d9", "relevance": 3, "abstract": "The application of LLM-based agents in financial investment has shown significant promise, yet existing approaches often require intermediate steps like predicting individual stock movements or rely on predefined, static workflows. These limitations restrict their adaptability and effectiveness in constructing optimal portfolios. In this paper, we introduce the Multi-Agent Scaling Simulation (MASS), a novel framework that leverages multi-agent simulation for direct, end-to-end portfolio construction. At its core, MASS employs a backward optimization process to dynamically learn the optimal distribution of heterogeneous agents, enabling the system to adapt to evolving market regimes. A key finding enabled by our framework is the exploration of the scaling effect for portfolio construction: we demonstrate that as the number of agents increases exponentially (up to 512), the aggregated decisions yield progressively higher excess returns. Extensive experiments on a challenging, self-collected dataset from the 2023 Chinese A-share market show that MASS consistently outperforms seven state-of-the-art baselines. Further backtesting, stability analyses and the experiment on data leakage concerns validate its enhanced profitability and robustness. We have open-sourced our code, dataset, and training snapshots at https://github.com/gta0804/MASS/ to foster further research.", "citations": 7}
{"title": "P1GPT: a multi-agent LLM workflow module for multi-modal financial information analysis", "year": 2025, "authors": "Chen-Che Lu, Yun-Cheng Chou, Teng-Ruei Chen", "url": "https://api.semanticscholar.org/CorpusId:282389311", "relevance": 3, "abstract": "Recent advances in large language models (LLMs) have enabled multi-agent reasoning systems capable of collaborative decision-making. However, in financial analysis, most frameworks remain narrowly focused on either isolated single-agent predictors or loosely connected analyst ensembles, and they lack a coherent reasoning workflow that unifies diverse data modalities. We introduce P1GPT, a layered multi-agent LLM framework for multi-modal financial information analysis and interpretable trading decision support. Unlike prior systems that emulate trading teams through role simulation, P1GPT implements a structured reasoning pipeline that systematically fuses technical, fundamental, and news-based insights through coordinated agent communication and integration-time synthesis. Backtesting on multi-modal datasets across major U.S. equities demonstrates that P1GPT achieves superior cumulative and risk-adjusted returns, maintains low drawdowns, and provides transparent causal rationales. These findings suggest that structured reasoning workflows, rather than agent role imitation, offer a scalable path toward explainable and trustworthy financial AI systems.", "citations": 0}
{"title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?", "year": 2025, "authors": "Weixian Waylon Li, Hyeonjun Kim, Mihai Cucuringu, Tiejun Ma", "url": "https://www.semanticscholar.org/paper/6d6354a0168e3d91c539032c28793ceb77f8092c", "relevance": 3, "abstract": "Large Language Models (LLMs) have recently been leveraged for asset pricing tasks and stock trading applications, enabling AI agents to generate investment decisions from unstructured financial data. However, most evaluations of LLM timing-based investing strategies are conducted on narrow timeframes and limited stock universes, overstating effectiveness due to survivorship and data-snooping biases. We critically assess their generalizability and robustness by proposing FINSABER, a backtesting framework evaluating timing-based strategies across longer periods and a larger universe of symbols. Systematic backtests over two decades and 100+ symbols reveal that previously reported LLM advantages deteriorate significantly under broader cross-section and over a longer-term evaluation. Our market regime analysis further demonstrates that LLM strategies are overly conservative in bull markets, underperforming passive benchmarks, and overly aggressive in bear markets, incurring heavy losses. These findings highlight the need to develop LLM strategies that are able to prioritise trend detection and regime-aware risk controls over mere scaling of framework complexity.", "citations": 7}
{"title": "FinPos: A Position-Aware Trading Agent System for Real Financial Markets", "year": 2025, "authors": "Bijia Liu, Ronghao Dang", "url": "https://www.semanticscholar.org/paper/a5cc3e3e464b0aa7703f6b707fdaab95f23ad26d", "relevance": 3, "abstract": "The exceptional potential of large language models (LLMs) in handling text information has garnered significant attention in the field of financial trading. However, most existing trading agents operate under intraday, independent unit-based trading tasks, where decisions are made as isolated directional actions, and thus lack awareness of continuous position management. Therefore, we propose a position-aware trading task designed to simulate a more realistic market. To address this task, we propose FinPos, a position-aware trading agent system designed to explicitly model and manage continuous positions. FinPos enhances position awareness through three key mechanisms: (1) professional-level interpretation of heterogeneous market information; (2) a dual-agent decision structure that separates directional reasoning from risk-aware position adjustment; and (3) multi-timescale reward signals, allowing the agent to internalize position awareness through experiential feedback rather than static instructions alone. Extensive experiments demonstrate that FinPos surpasses state-of-the-art trading agents in the position-aware trading task, which closely mirrors real market conditions. More importantly, our findings reveal that LLM-centered agent systems exhibit a vast, largely unexplored potential in long-term market decision-making.", "citations": 2}
{"title": "ATLAS: Adaptive Trading with LLM AgentS Through Dynamic Prompt Optimization and Multi-Agent Coordination", "year": 2025, "authors": "Charidimos Papadakis, Angeliki Dimitriou, Giorgos Filandrianos, Maria Lymperaiou, Konstantinos Thomas, G. Stamou", "url": "https://www.semanticscholar.org/paper/be8e14fdedf1b3edd32ae453e524f5b5ee727a7e", "relevance": 3, "abstract": "Large language models show promise for financial decision-making, yet deploying them as autonomous trading agents raises fundamental challenges: how to adapt instructions when rewards arrive late and obscured by market noise, how to synthesize heterogeneous information streams into coherent decisions, and how to bridge the gap between model outputs and executable market actions. We present ATLAS (Adaptive Trading with LLM AgentS), a unified multi-agent framework that integrates structured information from markets, news, and corporate fundamentals to support robust trading decisions. Within ATLAS, the central trading agent operates in an order-aware action space, ensuring that outputs correspond to executable market orders rather than abstract signals. The agent can incorporate feedback while trading using Adaptive-OPRO, a novel prompt-optimization technique that dynamically adapts the prompt by incorporating real-time, stochastic feedback, leading to increasing performance over time. Across regime-specific equity studies and multiple LLM families, Adaptive-OPRO consistently outperforms fixed prompts, while reflection-based feedback fails to provide systematic gains.", "citations": 1}
{"title": "TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?", "year": 2025, "authors": "Lewen Yan, Jilin Mei, Tianyi Zhou, Lige Huang, Jie Zhang, Dongrui Liu, Jing Shao", "url": "https://www.semanticscholar.org/paper/f85ceb388f4252862609da9d5bab478a116e2ed3", "relevance": 3, "abstract": "LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at https://github.com/Yanlewen/TradeTrap.", "citations": 1}
{"title": "FinRL Contests: Benchmarking Data-driven Financial Reinforcement Learning Agents", "year": 2025, "authors": "Keyi Wang, Nikolaus Holzer, Ziyi Xia, Yupeng Cao, Jiechao Gao, Anwar Walid, Kairong Xiao, Xiao-Yang Liu Yanglet", "url": "https://www.semanticscholar.org/paper/018e23442dbac6cd383c52be4200007821f06437", "relevance": 3, "abstract": "Financial reinforcement learning (FinRL) is now a practical paradigm for financial engineering. However, applying RL strategies to real-world trading tasks remains a challenge for individuals, as it is error-prone and engineering-heavy. The non-stationarity of financial data, low signal-to-noise ratios, and various market frictions require deep accumulations. Although numerous FinRL methods have been developed for tasks such as stock/crypto trading and portfolio management, the lack of standardized task definitions, real-time high-quality datasets, close-to-real market environments, and robust baselines has hindered consistent reproduction in both open-source community and FinTech industry. To bridge this gap, we organized a series of FinRL Contests from 2023 to 2025, covering a diverse range of financial tasks such as stock trading, order execution, crypto trading, and the use of large language model (LLM)-engineered signals. These contests attracted 200+ participants from 100+ institutions over 20+ countries. To encourage participations, we provided starter kits featuring GPU-optimized parallel market environments, ensemble learning, and comprehensive instructions. In this paper, we summarize these benchmarking efforts, detailing task formulations, data curation pipelines, environment implementations, evaluation protocols, participant performance, and organizational insights. It guides our follow-up FinRL contests, and also provides a reference for FinAI contests alike.", "citations": 3}
{"title": "Trade in Minutes! Rationality-Driven Agentic System for Quantitative Financial Trading", "year": 2025, "authors": "Zifan Song, Kaitao Song, Guosheng Hu, Ding Qi, Junyao Gao, Xiaohua Wang, Dongsheng Li, Cairong Zhao", "url": "https://www.semanticscholar.org/paper/c78c601e1fff91dd466cc0ee78db27654e604111", "relevance": 3, "abstract": "Recent advancements in large language models (LLMs) and agentic systems have shown exceptional decision-making capabilities, revealing significant potential for autonomic finance. Current financial trading agents predominantly simulate anthropomorphic roles that inadvertently introduce emotional biases and rely on peripheral information, while being constrained by the necessity for continuous inference during deployment. In this paper, we pioneer the harmonization of strategic depth in agents with the mechanical rationality essential for quantitative trading. Consequently, we present TiMi (Trade in Minutes), a rationality-driven multi-agent system that architecturally decouples strategy development from minute-level deployment. TiMi leverages specialized LLM capabilities of semantic analysis, code programming, and mathematical reasoning within a comprehensive policy-optimization-deployment chain. Specifically, we propose a two-tier analytical paradigm from macro patterns to micro customization, layered programming design for trading bot implementation, and closed-loop optimization driven by mathematical reflection. Extensive evaluations across 200+ trading pairs in stock and cryptocurrency markets empirically validate the efficacy of TiMi in stable profitability, action efficiency, and risk control under volatile market dynamics.", "citations": 1}
{"title": "Time Travel is Cheating: Going Live with DeepFund for Real-Time Fund Investment Benchmarking", "year": 2025, "authors": "Changlun Li, Yao Shi, Chen Wang, Qiqi Duan, Runke Ruan, Weijie Huang, Haonan Long, Lijun Huang, Yuyu Luo, Nan Tang", "url": "https://www.semanticscholar.org/paper/cd7438a5c5d731d744e9fce51bf702c6d3a8ffbd", "relevance": 3, "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across financial tasks, including financial report summarization, earnings call transcript analysis, and asset classification. However, their real-world effectiveness in managing complex fund investment remains inadequately assessed. A fundamental limitation of existing benchmarks for evaluating LLM-driven trading strategies is their reliance on historical back-testing, inadvertently enabling LLMs to\"time travel\"-leveraging future information embedded in their training corpora, thus resulting in possible information leakage and overly optimistic performance estimates. To address this issue, we introduce DeepFund, a live fund benchmark tool designed to rigorously evaluate LLM in real-time market conditions. Utilizing a multi-agent architecture, DeepFund connects directly with real-time stock market data-specifically data published after each model pretraining cutoff-to ensure fair and leakage-free evaluations. Empirical tests on nine flagship LLMs from leading global institutions across multiple investment dimensions-including ticker-level analysis, investment decision-making, portfolio management, and risk control-reveal significant practical challenges. Notably, even cutting-edge models such as DeepSeek-V3 and Claude-3.7-Sonnet incur net trading losses within DeepFund real-time evaluation environment, underscoring the present limitations of LLMs for active fund management. Our code is available at https://github.com/HKUSTDial/DeepFund.", "citations": 6}
{"title": "FinArena: A Human-Agent Collaboration Framework for Financial Market Analysis and Forecasting", "year": 2025, "authors": "Congluo Xu, Zhaobin Liu, Ziyang Li", "url": "https://www.semanticscholar.org/paper/f18b6564594bc3f3326ba174416e7e7d9e61f2db", "relevance": 3, "abstract": "To improve stock trend predictions and support personalized investment decisions, this paper proposes FinArena, a novel Human-Agent collaboration framework. Inspired by the mixture of experts (MoE) approach, FinArena combines multimodal financial data analysis with user interaction. The human module features an interactive interface that captures individual risk preferences, allowing personalized investment strategies. The machine module utilizes a Large Language Model-based (LLM-based) multi-agent system to integrate diverse data sources, such as stock prices, news articles, and financial statements. To address hallucinations in LLMs, FinArena employs the adaptive Retrieval-Augmented Generative (RAG) method for processing unstructured news data. Finally, a universal expert agent makes investment decisions based on the features extracted from multimodal data and investors' individual risk preferences. Extensive experiments show that FinArena surpasses both traditional and state-of-the-art benchmarks in stock trend prediction and yields promising results in trading simulations across various risk profiles. These findings highlight FinArena's potential to enhance investment outcomes by aligning strategic insights with personalized risk considerations.", "citations": 7}
{"title": "AlphaQuanter: An End-to-End Tool-Orchestrated Agentic Reinforcement Learning Framework for Stock Trading", "year": 2025, "authors": "Zheye Deng, Jiashu Wang", "url": "https://www.semanticscholar.org/paper/acf01e45c8caa3de4076da78ecf2aff8adc99dca", "relevance": 3, "abstract": "While Large Language Model (LLM) agents show promise in automated trading, they still face critical limitations. Prominent multi-agent frameworks often suffer from inefficiency, produce inconsistent signals, and lack the end-to-end optimization required to learn a coherent strategy from market feedback. To address this, we introduce AlphaQuanter, a single-agent framework that uses reinforcement learning (RL) to learn a dynamic policy over a transparent, tool-augmented decision workflow, which empowers a single agent to autonomously orchestrate tools and proactively acquire information on demand, establishing a transparent and auditable reasoning process. Extensive experiments demonstrate that AlphaQuanter achieves state-of-the-art performance on key financial metrics. Moreover, its interpretable reasoning reveals sophisticated strategies, offering novel and valuable insights for human traders. Our code for data acquisition and agent training is publicly available at: https://github.com/AlphaQuanter/AlphaQuanter", "citations": 0}
{"title": "Advancing Financial Engineering with Foundation Models: Progress, Applications, and Challenges", "year": 2025, "authors": "Liyuan Chen, Shuoling Liu, Jiangpeng Yan, Xiaoyu Wang, Henglin Liu, Chuang Li, Kechen Jiao, Jixuan Ying, Yang Liu, Qiang Yang, Xiu Li", "url": "https://www.semanticscholar.org/paper/390a6229243d7cc42bf756fc9564b9c48dd43b6f", "relevance": 3, "abstract": "", "citations": 2}
{"title": "Language Model Guided Reinforcement Learning in Quantitative Trading", "year": 2025, "authors": "Adam Darmanin, Vince Vella", "url": "https://www.semanticscholar.org/paper/33b67564618fe3cb89d839890697808830151603", "relevance": 3, "abstract": "Algorithmic trading requires short-term tactical decisions consistent with long-term financial objectives. Reinforcement Learning (RL) has been applied to such problems, but adoption is limited by myopic behaviour and opaque policies. Large Language Models (LLMs) offer complementary strategic reasoning and multi-modal signal interpretation when guided by well-structured prompts. This paper proposes a hybrid framework in which LLMs generate high-level trading strategies to guide RL agents. We evaluate (i) the economic rationale of LLM-generated strategies through expert review, and (ii) the performance of LLM-guided agents against unguided RL baselines using Sharpe Ratio (SR) and Maximum Drawdown (MDD). Empirical results indicate that LLM guidance improves both return and risk metrics relative to standard RL.", "citations": 1}
{"title": "QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading", "year": 2025, "authors": "Fei Xiong, Xiang Zhang, Aosong Feng, Siqi Sun, Chenyu You", "url": "https://www.semanticscholar.org/paper/23aab54ccfd0b5ac0f9995a02ebb7d0765ce4914", "relevance": 3, "abstract": "Recent advances in Large Language Models (LLMs) have shown remarkable capabilities in financial reasoning and market understanding. Multi-agent LLM frameworks such as TradingAgent and FINMEM augment these models to long-horizon investment tasks by leveraging fundamental and sentiment-based inputs for strategic decision-making. However, these approaches are ill-suited for the high-speed, precision-critical demands of High-Frequency Trading (HFT). HFT typically requires rapid, risk-aware decisions driven by structured, short-horizon signals, such as technical indicators, chart patterns, and trend features. These signals stand in sharp contrast to the long-horizon, text-driven reasoning that characterizes most existing LLM-based systems in finance. To bridge this gap, we introduce QuantAgent, the first multi-agent LLM framework explicitly designed for high-frequency algorithmic trading. The system decomposes trading into four specialized agents--Indicator, Pattern, Trend, and Risk--each equipped with domain-specific tools and structured reasoning capabilities to capture distinct aspects of market dynamics over short temporal windows. Extensive experiments across nine financial instruments, including Bitcoin and Nasdaq futures, demonstrate that QuantAgent consistently outperforms baseline methods, achieving higher predictive accuracy at both 1-hour and 4-hour trading intervals across multiple evaluation metrics. Our findings suggest that coupling structured trading signals with LLM-based reasoning provides a viable path for traceable, real-time decision systems in high-frequency financial markets.", "citations": 5}
{"title": "Autonomous Market Intelligence: Agentic AI Nowcasting Predicts Stock Returns", "year": 2026, "authors": "Darcy Pu, Zefeng Chen", "url": "https://www.semanticscholar.org/paper/9bc1def360e0f4fb3364f680bb889c06708eeab8", "relevance": 3, "abstract": "Can fully agentic AI nowcast stock returns? We deploy a state-of-the-art Large Language Model to evaluate the attractiveness of each Russell 1000 stock daily, starting from April 2025 when AI web interfaces enabled real-time search. Our data contribution is unique along three dimensions. First, the nowcasting framework is completely out-of-sample and free of look-ahead bias by construction: predictions are collected at the current edge of time, ensuring the AI has no knowledge of future outcomes. Second, this temporal design is irreproducible-once the information environment passes, it can never be recreated. Third, our framework is 100% agentic: we do not feed the model news, disclosures, or curated text; it autonomously searches the web, filters sources, and synthesises information into quantitative predictions. We find that AI possesses genuine stock selection ability, but only for identifying top winners. Longing the 20 highest-ranked stocks generates a daily Fama-French five-factor plus momentum alpha of 18.5 basis points and an annualised Sharpe ratio of 2.43. Critically, these returns derive from an implementable strategy trading highly liquid Russell 1000 constituents, with transaction costs representing less than 10% of gross alpha. However, this predictability is highly concentrated: expanding beyond the top tier rapidly dilutes alpha, and bottom-ranked stocks exhibit returns statistically indistinguishable from the market. We hypothesise that this asymmetry reflects online information structure: genuinely positive news generates coherent signals, while negative news is contaminated by strategic corporate obfuscation and social media noise.", "citations": 0}
{"title": "QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large Language Model", "year": 2024, "authors": "Sai Wang, Hang Yuan, Lionel M. Ni, Jian Guo", "url": "https://www.semanticscholar.org/paper/83edf6872534c75b3099c0b456472e68d6d89ed2", "relevance": 3, "abstract": "Autonomous agents based on Large Language Models (LLMs) that devise plans and tackle real-world challenges have gained prominence.However, tailoring these agents for specialized domains like quantitative investment remains a formidable task. The core challenge involves efficiently building and integrating a domain-specific knowledge base for the agent's learning process. This paper introduces a principled framework to address this challenge, comprising a two-layer loop.In the inner loop, the agent refines its responses by drawing from its knowledge base, while in the outer loop, these responses are tested in real-world scenarios to automatically enhance the knowledge base with new insights.We demonstrate that our approach enables the agent to progressively approximate optimal behavior with provable efficiency.Furthermore, we instantiate this framework through an autonomous agent for mining trading signals named QuantAgent. Empirical results showcase QuantAgent's capability in uncovering viable financial signals and enhancing the accuracy of financial forecasts.", "citations": 26}
{"title": "AlphaAgents: Large Language Model based Multi-Agents for Equity Portfolio Constructions", "year": 2025, "authors": "Tianjiao Zhao, Jingrao Lyu, Stokes Jones, Harrison Garber, Stefano Pasquali, Dhagash Mehta", "url": "https://api.semanticscholar.org/CorpusId:280671159", "relevance": 3, "abstract": "The field of artificial intelligence (AI) agents is evolving rapidly, driven by the capabilities of Large Language Models (LLMs) to autonomously perform and refine tasks with human-like efficiency and adaptability. In this context, multi-agent collaboration has emerged as a promising approach, enabling multiple AI agents to work together to solve complex challenges. This study investigates the application of role-based multi-agent systems to support stock selection in equity research and portfolio management. We present a comprehensive analysis performed by a team of specialized agents and evaluate their stock-picking performance against established benchmarks under varying levels of risk tolerance. Furthermore, we examine the advantages and limitations of employing multi-agent frameworks in equity analysis, offering critical insights into their practical efficacy and implementation challenges.", "citations": 4}
{"title": "LLM Agents Do Not Replicate Human Market Traders: Evidence From Experimental Finance", "year": 2025, "authors": "Thomas Henning, Siddhartha Ojha, Ross Spoon, Jiatong Han, C. F. Camerer", "url": "https://www.semanticscholar.org/paper/f8e803933490215a0c0db279749ccaeaf29f4086", "relevance": 3, "abstract": "This paper explores how Large Language Models (LLMs) behave in a classic experimental finance paradigm widely known for eliciting bubbles and crashes in human participants. We adapt an established trading design, where traders buy and sell a risky asset with a known fundamental value, and introduce several LLM-based agents, both in single-model markets (all traders are instances of the same LLM) and in mixed-model\"battle royale\"settings (multiple LLMs competing in the same market). Our findings reveal that LLMs generally exhibit a\"textbook-rational\"approach, pricing the asset near its fundamental value, and show only a muted tendency toward bubble formation. Further analyses indicate that LLM-based agents display less trading strategy variance in contrast to humans. Taken together, these results highlight the risk of relying on LLM-only data to replicate human-driven market phenomena, as key behavioral features, such as large emergent bubbles, were not robustly reproduced. While LLMs clearly possess the capacity for strategic decision-making, their relative consistency and rationality suggest that they do not accurately mimic human market dynamics.", "citations": 3}
{"title": "MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents", "year": 2025, "authors": "George Fatouros, Kostas C. Metaxas, John Soldatos, Manos Karathanassis", "url": "https://www.semanticscholar.org/paper/f937b109dbc2bb4c831af3b63487bf001834cef0", "relevance": 3, "abstract": "MarketSenseAI is a novel framework for holistic stock analysis which leverages Large Language Models (LLMs) to process financial news, historical prices, company fundamentals and the macroeconomic environment to support decision making in stock analysis and selection. In this paper, we present the latest advancements on MarketSenseAI, driven by rapid technological expansion in LLMs. Through a novel architecture combining Retrieval-Augmented Generation and LLM agents, the framework processes SEC filings and earnings calls, while enriching macroeconomic analysis through systematic processing of diverse institutional reports. We demonstrate a significant improvement in fundamental analysis accuracy over the previous version. Empirical evaluation on S\\&P 100 stocks over two years (2023-2024) shows MarketSenseAI achieving cumulative returns of 125.9% compared to the index return of 73.5%, while maintaining comparable risk profiles. Further validation on S\\&P 500 stocks during 2024 demonstrates the framework's scalability, delivering a 33.8% higher Sortino ratio than the market. This work marks a significant advancement in applying LLM technology to financial analysis, offering insights into the robustness of LLM-driven investment strategies.", "citations": 11}
{"title": "Will LLMs be Professional at Fund Investment? DeepFund: A Live Arena Perspective", "year": 2025, "authors": "Changlun Li, Yao Shi, Yuyu Luo, Nan Tang", "url": "https://www.semanticscholar.org/paper/67c606df1d20ee804ce586f3aa899652b2639781", "relevance": 3, "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across various domains, but their effectiveness in financial decision-making remains inadequately evaluated. Current benchmarks primarily assess LLMs'understanding on financial documents rather than the ability to manage assets or dig out trading opportunities in dynamic market conditions. Despite the release of new benchmarks for evaluating diversified tasks on the financial domain, we identified four major problems in these benchmarks, which are data leakage, navel-gazing, over-intervention, and maintenance-hard. To pave the research gap, we introduce DeepFund, a comprehensive arena platform for evaluating LLM-based trading strategies in a live environment. Our approach implements a multi-agent framework where they serve as multiple key roles that realize the real-world investment decision processes. Moreover, we provide a web interface that visualizes LLMs'performance with fund investment metrics across different market conditions, enabling detailed comparative analysis. Through DeepFund, we aim to provide a more realistic and fair assessment on LLM's capabilities in fund investment, offering diversified insights and revealing their potential applications in real-world financial markets. Our code is publicly available at https://github.com/HKUSTDial/DeepFund.", "citations": 2}
{"title": "Adaptive and Explainable Margin Trading via Large Language Models on Portfolio Management", "year": 2024, "authors": "Jingyi Gu, J. Ye, Guiling Wang, Wenpeng Yin", "url": "https://api.semanticscholar.org/CorpusId:274086023", "relevance": 3, "abstract": "Recent strategies for portfolio management often lack flexibility to adjust funds between long and short positions throughout trading periods. This prevents adapting portfolios to the market, which mitigates risks and seizes opportunities. To address these gaps, we propose an adaptive and explainable framework that integrates Large Language Models (LLMs) with Reinforcement Learning (RL) for dynamic long-short position adjustment in response to evolving market conditions. This approach leverages the recent advancements in LLMs for processing unstructured data and their capacity for explainable reasoning. The framework includes two stages: an Explainable Market Forecasting/Reasoning Pipeline, and a Position Reallocation stage. The Market Forecasting/Reasoning Pipeline allows various LLMs to learn market trends from diverse external data sources and determine optimal adjustment ratios with a clear reasoning path. The Portfolio Reallocation stage interacts with the sequential trading process from a pre-trained RL model to enhance decision-making and transparency. Our framework is flexible to accommodate various external data sources from microeconomics to macroeconomics data, diverse data types including time series and news text, along with multiple LLMs. Experiments demonstrate that our framework effectively achieves three times the return and doubles the Sharpe ratio compared to benchmarks. All the data and code are publicly available under NJIT FinTech Lab\u2019s GitHub1.", "citations": 8}
{"title": "FinRL-DeepSeek: LLM-Infused Risk-Sensitive Reinforcement Learning for Trading Agents", "year": 2025, "authors": "Mostapha Benhenda", "url": "https://www.semanticscholar.org/paper/49be1120557f0dc74580aa2a2196354e9b188a99", "relevance": 3, "abstract": "This paper presents a novel risk-sensitive trading agent combining reinforcement learning and large language models (LLMs). We extend the Conditional Value-at-Risk Proximal Policy Optimization (CPPO) algorithm, by adding risk assessment and trading recommendation signals generated by a LLM from financial news. Our approach is backtested on the Nasdaq-100 index benchmark, using financial news data from the FNSPID dataset and the DeepSeek V3, Qwen 2.5 and Llama 3.3 language models. The code, data, and trading agents are available at: https://github.com/benstaf/FinRL_DeepSeek", "citations": 14}
{"title": "Behavioral Consistency Validation for LLM Agents: An Analysis of Trading-Style Switching through Stock-Market Simulation", "year": 2026, "authors": "Zeping Li, Guancheng Wan, Keyang Chen, Yu Chen, Yiwen Zhao, Philip Torr, Guangnan Ye, Zhenfei Yin, Hongfeng Chai", "url": "https://www.semanticscholar.org/paper/7550169d076668ede36673525ad2b96baa54fe0a", "relevance": 3, "abstract": "Recent works have increasingly applied Large Language Models (LLMs) as agents in financial stock market simulations to test if micro-level behaviors aggregate into macro-level phenomena. However, a crucial question arises: Do LLM agents'behaviors align with real market participants? This alignment is key to the validity of simulation results. To explore this, we select a financial stock market scenario to test behavioral consistency. Investors are typically classified as fundamental or technical traders, but most simulations fix strategies at initialization, failing to reflect real-world trading dynamics. In this work, we assess whether agents'strategy switching aligns with financial theory, providing a framework for this evaluation. We operationalize four behavioral-finance drivers-loss aversion, herding, wealth differentiation, and price misalignment-as personality traits set via prompting and stored long-term. In year-long simulations, agents process daily price-volume data, trade under a designated style, and reassess their strategy every 10 trading days. We introduce four alignment metrics and use Mann-Whitney U tests to compare agents'style-switching behavior with financial theory. Our results show that recent LLMs'switching behavior is only partially consistent with behavioral-finance theories, highlighting the need for further refinement in aligning agent behavior with financial theory.", "citations": 0}
{"title": "TradExpert: Revolutionizing Trading with Mixture of Expert LLMs", "year": 2024, "authors": "Qianggang Ding, Haochen Shi, Bang Liu", "url": "https://www.semanticscholar.org/paper/c5a44c7ec06162d8d505c780deba49e30252780a", "relevance": 3, "abstract": "The integration of Artificial Intelligence (AI) in the financial domain has opened new avenues for quantitative trading, particularly through the use of Large Language Models (LLMs). However, the challenge of effectively synthesizing insights from diverse data sources and integrating both structured and unstructured data persists. This paper presents TradeExpert, a novel framework that employs a mix of experts (MoE) approach, using four specialized LLMs, each analyzing distinct sources of financial data, including news articles, market data, alpha factors, and fundamental data. The insights of these expert LLMs are further synthesized by a General Expert LLM to make a final prediction or decision. With specific prompts, TradeExpert can be switched between the prediction mode and the ranking mode for stock movement prediction and quantitative stock trading, respectively. In addition to existing benchmarks, we also release a large-scale financial dataset to comprehensively evaluate TradeExpert's effectiveness. Our experimental results demonstrate TradeExpert's superior performance across all trading scenarios.", "citations": 10}
{"title": "HedgeAgents: A Balanced-aware Multi-agent Financial Trading System", "year": 2025, "authors": "Xiangyu Li, Yawen Zeng, Xiaofen Xing, Jin Xu, Xiangmin Xu", "url": "https://www.semanticscholar.org/paper/701cd738cbdeb49b9cd9f2de3ee90d61d066faf5", "relevance": 2, "abstract": "As automated trading gains traction in the financial market, algorithmic investment strategies are increasingly prominent. While Large Language Models (LLMs) and Agent-based models exhibit promising potential in real-time market analysis and trading decisions, they still experience a significant -20% loss when confronted with rapid declines or frequent fluctuations, impeding their practical application. Hence, there is an imperative to explore a more robust and resilient framework. This paper introduces an innovative multi-agent system, HedgeAgents, aimed at bolstering system robustness via ''hedging'' strategies. In this well-balanced system, an array of hedging agents has been tailored, where HedgeAgents consist of a central fund manager and multiple hedging experts specializing in various financial asset classes. These agents leverage LLMs' cognitive capabilities to make decisions and coordinate through three types of conferences. Benefiting from the powerful understanding of LLMs, our HedgeAgents attained a 70% annualized return and a 400% total return over a period of 3 years. Moreover, we have observed with delight that HedgeAgents can even formulate investment experience comparable to those of human experts (https://hedgeagents.github.io/).", "citations": 23}
{"title": "A Survey of Large Language Models for Financial Applications: Progress, Prospects and Challenges", "year": 2024, "authors": "Yuqi Nie, Yaxuan Kong, Xiaowen Dong, John M. Mulvey, H. Poor, Qingsong Wen, Stefan Zohren", "url": "https://www.semanticscholar.org/paper/8663871588271b4f20645fefcc7d25d9bd1547cf", "relevance": 2, "abstract": "Recent advances in large language models (LLMs) have unlocked novel opportunities for machine learning applications in the financial domain. These models have demonstrated remarkable capabilities in understanding context, processing vast amounts of data, and generating human-preferred contents. In this survey, we explore the application of LLMs on various financial tasks, focusing on their potential to transform traditional practices and drive innovation. We provide a discussion of the progress and advantages of LLMs in financial contexts, analyzing their advanced technologies as well as prospective capabilities in contextual understanding, transfer learning flexibility, complex emotion detection, etc. We then highlight this survey for categorizing the existing literature into key application areas, including linguistic tasks, sentiment analysis, financial time series, financial reasoning, agent-based modeling, and other applications. For each application area, we delve into specific methodologies, such as textual analysis, knowledge-based analysis, forecasting, data augmentation, planning, decision support, and simulations. Furthermore, a comprehensive collection of datasets, model assets, and useful codes associated with mainstream applications are presented as resources for the researchers and practitioners. Finally, we outline the challenges and opportunities for future research, particularly emphasizing a number of distinctive aspects in this field. We hope our work can help facilitate the adoption and further development of LLMs in the financial sector.", "citations": 125}
{"title": "The Evolution of Alpha in Finance Harnessing Human Insight and LLM Agents", "year": 2025, "authors": "Mohammad Rubyet Islam", "url": "https://api.semanticscholar.org/CorpusId:278782847", "relevance": 2, "abstract": "The pursuit of alpha returns that exceed market benchmarks has undergone a profound transformation, evolving from intuition-driven investing to autonomous, AI powered systems. This paper introduces a comprehensive five stage taxonomy that traces this progression across manual strategies, statistical models, classical machine learning, deep learning, and agentic architectures powered by large language models (LLMs). Unlike prior surveys focused narrowly on modeling techniques, this review adopts a system level lens, integrating advances in representation learning, multimodal data fusion, and tool augmented LLM agents. The strategic shift from static predictors to contextaware financial agents capable of real time reasoning, scenario simulation, and cross modal decision making is emphasized. Key challenges in interpretability, data fragility, governance, and regulatory compliance areas critical to production deployment are examined. The proposed taxonomy offers a unified framework for evaluating maturity, aligning infrastructure, and guiding the responsible development of next generation alpha systems.", "citations": 4}
{"title": "LLM-Powered AI Agent Systems and Their Applications in Industry", "year": 2025, "authors": "Guannan Liang, Qianqian Tong", "url": "https://api.semanticscholar.org/CorpusId:278789054", "relevance": 2, "abstract": "The emergence of Large Language Models (LLMs) has reshaped agent systems. Unlike traditional rule-based agents with limited task scope, LLM-powered agents offer greater flexibility, cross-domain reasoning, and natural language interaction. Moreover, with the integration of multi-modal LLMs, current agent systems are highly capable of processing diverse data modalities, including text, images, audio, and structured tabular data, enabling richer and more adaptive real-world behavior. This paper comprehensively examines the evolution of agent systems from the pre-LLM era to current LLM-powered architectures. We categorize agent systems into software-based, physical, and adaptive hybrid systems, highlighting applications across customer service, software development, manufacturing automation, personalized education, financial trading, and healthcare. We further discuss the primary challenges posed by LLM-powered agents, including high inference latency, output uncertainty, lack of evaluation metrics, and security vulnerabilities, and propose potential solutions to mitigate these concerns.", "citations": 17}
{"title": "Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models", "year": 2024, "authors": "Kelvin J.L. Koa, Yunshan Ma, Ritchie Ng, Tat-Seng Chua", "url": "https://www.semanticscholar.org/paper/a734edb6c3d70eec77ddb4504b2df87c3b74b77c", "relevance": 1, "abstract": "Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a verbal self-reflective agent and Proximal Policy Optimization (PPO) that allow a LLM teach itself how to generate explainable stock predictions, in a fully autonomous manner. The reflective agent learns how to explain past stock movements through a self-reasoning process, while the PPO trainer trains the model to generate the most likely explanations given the input texts at test-time. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a specialized LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient, for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics. Our code can be accessed through https://github.com/koa-fin/sep.", "citations": 50}
{"title": "AI in Investment Analysis: LLMs for Equity Stock Ratings", "year": 2024, "authors": "Kassiani Papasotiriou, Srijan Sood, Shayleen Reynolds, T. Balch", "url": "https://www.semanticscholar.org/paper/84c19da4f76fedb40faf515d6d65d387323743f6", "relevance": 1, "abstract": "Investment Analysis is a cornerstone of the Financial Services industry. The rapid integration of advanced machine learning techniques, particularly Large Language Models (LLMs), offers opportunities to enhance the equity stock rating process. This paper explores the application of LLMs to predict stock performance and generate stock ratings by ingesting diverse datasets. Traditional stock rating methods rely heavily on the expertise of financial analysts, and face several challenges such as data overload, inconsistencies in filings, and delayed reactions to market events. Our study addresses these issues by leveraging LLMs to improve the accuracy and consistency of stock ratings. Additionally, we assess the efficacy of using different data modalities with LLMs for the financial domain. We utilize varied datasets comprising fundamental financial, market, and news data from January 2022 to June 2024, along with GPT-4-32k (v0613) (with a training cutoff in Sep. 2021 to prevent information leakage). Our results show that our benchmark method outperforms traditional stock rating methods when assessed by forward returns. Specifically, incorporating financial fundamentals enhances ratings accuracy. While integrating news data improves short-term performance, substituting detailed news summaries with sentiment scores reduces token use without loss of performance. In many cases, omitting news data entirely enhances performance by reducing bias. Our research shows that LLMs can be leveraged to effectively utilize large amounts of multimodal financial data, as showcased by their effectiveness at the stock rating prediction task. Our work provides a reproducible framework for generating consistent and accurate stock ratings, offering a cost-effective and efficient alternative to traditional methods. Future work will extend the analysis to longer time horizons, incorporating more diverse data, and utilizing newer models to enhance detailed investment analysis and reports.", "citations": 12}
{"title": "R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization", "year": 2025, "authors": "Yuante Li, Xu Yang, Xiao Yang, Minrui Xu, Xisen Wang, Weiqing Liu, Jiang Bian", "url": "https://www.semanticscholar.org/paper/84d641eeeeef5cb1d01fe4d1798024a409534af3", "relevance": 1, "abstract": "Financial markets pose fundamental challenges for asset return prediction due to their high dimensionality, non-stationarity, and persistent volatility. Despite advances in large language models and multi-agent systems, current quantitative research pipelines suffer from limited automation, weak interpretability, and fragmented coordination across key components such as factor mining and model innovation. In this paper, we propose R&D-Agent for Quantitative Finance, in short RD-Agent(Q), the first data-centric multi-agent framework designed to automate the full-stack research and development of quantitative strategies via coordinated factor-model co-optimization. RD-Agent(Q) decomposes the quant process into two iterative stages: a Research stage that dynamically sets goal-aligned prompts, formulates hypotheses based on domain priors, and maps them to concrete tasks, and a Development stage that employs a code-generation agent, Co-STEER, to implement task-specific code, which is then executed in real-market backtests. The two stages are connected through a feedback stage that thoroughly evaluates experimental outcomes and informs subsequent iterations, with a multi-armed bandit scheduler for adaptive direction selection. Empirically, RD-Agent(Q) achieves up to 2X higher annualized returns than classical factor libraries using 70% fewer factors, and outperforms state-of-the-art deep time-series models on real markets. Its joint factor-model optimization delivers a strong balance between predictive accuracy and strategy robustness. Our code is available at: https://github.com/microsoft/RD-Agent.", "citations": 11}
{"title": "Enhancing FinRL Trading Agents with Advance LLM-Processed Financial News: An Improved Approach Using DeepSeek-V3", "year": 2025, "authors": "Satish Chandra, Dr. G. Balakrishna", "url": "https://www.semanticscholar.org/paper/3c02fb508f68567336afdfcaa6c552e4a9c40eeb", "relevance": 1, "abstract": "The use of AI techniques to improve stock market related operations has been benefiting traders in the stock market. FinRL is a framework that has been shown to be effective in building Reinforcement Learning (RL) based Trading Agents. Use of LLMs for performance improvement of the Agents is one of the recent initiatives. LLMs are being used to generate signals that could be combined with historical stock prices for better prediction of stock price movement trends leading to profitable trading. This paper aims to develop efficiently engineered prompts to generate DeepSeek-V3-based sentiment signals, integrate them into the FinRL environment, and improve the performance of reinforcement learning trading agents. The code, data, and trading agents are at: https://github.com/SatishChandraPhD/FinRL2025", "citations": 0}
{"title": "FinRL Contest 2025 Task 1:Market-Aware In-Context Learning Framework for Proximal Policy Optimization in Stock Trading Using DeepSeek", "year": 2025, "authors": "Sahar Arshad, Huma Ameer, Nikhar Azhar, Seemab Latif", "url": "https://www.semanticscholar.org/paper/997ba1f06381f495e1f8da0b444a84dee41ad29c", "relevance": 1, "abstract": "This paper introduces a Market-Cap Stratified Subset (MCSS) strategy. It constructs a balanced, high-quality dataset from the Financial News and Stock Price Integration Dataset (FNSPID). Building on MCSS, we propose Market-Informed Sentiment for Trading (MIST). This is a two-phase framework that first generates sentiment scores through optimized prompt engineering with LLMs, then aligns market movements to deliver actionable trading signals. With a Proximal Policy Optimization (PPO)-based agent, MIST achieves better policy stability and learning efficiency than baseline methods.", "citations": 3}
{"title": "FinLlama: LLM-Based Financial Sentiment Analysis for Algorithmic Trading", "year": 2024, "authors": "Giorgos Iacovides, Thanos Konstantinidis, Mingxue Xu, Danilo Mandic", "url": "https://www.semanticscholar.org/paper/d798dea2a4e995e08de033809ec3fd63c53d8b46", "relevance": 1, "abstract": "Online sources of financial news have a profound influence on both market movements and trading decisions. Standard sentiment analysis employs a lexicon-based approach to aid financial decisions, but struggles with context sensitivity and word ordering. On the other hand, Large Language Models (LLMs) are powerful, but are not finance-specific and require significant computational resources. To this end, we introduce a finance specific LLM framework, based on the Llama 2 7B foundational model, in order to benefit from its generative nature and comprehensive language manipulation. Such a generator-discriminator scheme, referred to as FinLlama, both classifies sentiment valence and quantifies its strength, offering a nuanced insight into financial news. The FinLlama model is fine-tuned on supervised financial sentiment analysis data, to make it handle the complexities of financial lexicon and context, and is equipped with a neural network-based decision mechanism. The subsequent parameter-efficient fine-tuning optimises trainable parameters, thus minimising computational and memory requirements without sacrificing accuracy. Simulation results demonstrate the ability of FinLlama to increase market returns in portfolio management scenarios, yielding high-return and resilient portfolios, even during volatile periods.", "citations": 33}
{"title": "TraderTalk: An LLM Behavioural ABM applied to Simulating Human Bilateral Trading Interactions", "year": 2024, "authors": "Alicia Vidler, Toby Walsh", "url": "https://api.semanticscholar.org/CorpusId:273661563", "relevance": 1, "abstract": "We introduce a novel hybrid approach that augments Agent-Based Models (ABMs) with behaviours generated by Large Language Models (LLMs) to simulate human trading interactions. We call our model TraderTalk. Leveraging LLMs trained on extensive human-authored text, we capture detailed and nuanced representations of bilateral conversations in financial trading. Applying this Generative Agent-Based Model (GABM) to government bond markets, we replicate trading decisions between two stylised virtual humans. Our method addresses both structural challenges\u2014such as coordinating turn-taking between realistic LLM-based agents\u2014and design challenges, including the interpretation of LLM outputs by the agent model. By exploring prompt design opportunistically rather than systematically, we enhance the realism of agent interactions without exhaustive overfitting or model reliance. Our approach successfully replicates trade-to-order volume ratios observed in related asset markets, demonstrating the potential of LLM-augmented ABMs in financial simulations.", "citations": 3}
{"title": "Advanced simulation paradigm of human behaviour unveils complex financial systemic projection", "year": 2025, "authors": "Cheng Wang, Chuwen Wang, Shirong Zeng, Jianguo Liu, Changjun Jiang", "url": "https://api.semanticscholar.org/CorpusId:277349490", "relevance": 1, "abstract": "The high-order complexity of human behaviour is likely the root cause of extreme difficulty in financial market projections. We consider that behavioural simulation can unveil systemic dynamics to support analysis. Simulating diverse human groups must account for the behavioural heterogeneity, especially in finance. To address the fidelity of simulated agents, on the basis of agent-based modeling, we propose a new paradigm of behavioural simulation where each agent is supported and driven by a hierarchical knowledge architecture. This architecture, integrating language and professional models, imitates behavioural processes in specific scenarios. Evaluated on futures markets, our simulator achieves a 13.29% deviation in simulating crisis scenarios whose price increase rate reaches 285.34%. Under normal conditions, our simulator also exhibits lower mean square error in predicting futures price of specific commodities. This technique bridges non-quantitative information with diverse market behaviour, offering a promising platform to simulate investor behaviour and its impact on market dynamics.", "citations": 0}
{"title": "Financial News-Driven LLM Reinforcement Learning for Portfolio Management", "year": 2024, "authors": "Ananya Unnikrishnan", "url": "https://www.semanticscholar.org/paper/fe68b7829b7a7e77beb4fefd8f81211751d1a41c", "relevance": 1, "abstract": "Reinforcement learning (RL) has emerged as a transformative approach for financial trading, enabling dynamic strategy optimization in complex markets. This study explores the integration of sentiment analysis, derived from large language models (LLMs), into RL frameworks to enhance trading performance. Experiments were conducted on single-stock trading with Apple Inc. (AAPL) and portfolio trading with the ING Corporate Leaders Trust Series B (LEXCX). The sentiment-enhanced RL models demonstrated superior net worth and cumulative profit compared to RL models without sentiment and, in the portfolio experiment, outperformed the actual LEXCX portfolio's buy-and-hold strategy. These results highlight the potential of incorporating qualitative market signals to improve decision-making, bridging the gap between quantitative and qualitative approaches in financial trading.", "citations": 5}
{"title": "ElliottAgents: A Natural Language-Driven Multi-Agent System for Stock Market Analysis and Prediction", "year": 2025, "authors": "Jaros\u0142aw A. Chudziak, Micha\u0142 Wawer", "url": "https://www.semanticscholar.org/paper/0afc77a7ed85377917f818a404c8e5acaf0626be", "relevance": 1, "abstract": "This paper presents ElliottAgents, a multi-agent system leveraging natural language processing (NLP) and large language models (LLMs) to analyze complex stock market data. The system combines AI-driven analysis with the Elliott Wave Principle to generate human-comprehensible predictions and explanations. A key feature is the natural language dialogue between agents, enabling collaborative analysis refinement. The LLM-enhanced architecture facilitates advanced language understanding, reasoning, and autonomous decision-making. Experiments demonstrate the system's effectiveness in pattern recognition and generating natural language descriptions of market trends. ElliottAgents contributes to NLP applications in specialized domains, showcasing how AI-driven dialogue systems can enhance collaborative analysis in data-intensive fields. This research bridges the gap between complex financial data and human understanding, addressing the need for interpretable and adaptive prediction systems in finance.", "citations": 12}
{"title": "Enhanced Financial Sentiment Analysis and Trading Strategy Development Using Large Language Models", "year": 2024, "authors": "Kemal Kirtac, Guido Germano", "url": "https://api.semanticscholar.org/CorpusId:271769615", "relevance": 1, "abstract": "This study examines a novel methodology for enhanced financial sentiment analysis and trading strategy development using large language models (LLMs) such as OPT, BERT, FinBERT, LLAMA 3, and RoBERTa. Utilizing a dataset of 965,375 U.S. financial news articles from 2010 to 2023, our research demonstrates that the GPT-3-based OPT significantly outperforms other models, achieving a prediction accuracy of 74.4% for stock market returns. Our findings reveal that the advanced capabilities of LLMs, particularly OPT, surpass traditional sentiment analysis methods such as the Loughran-McDonald dictionary model in predicting and explaining stock returns. For instance, a self-financing strategy based on OPT scores achieves a Sharpe ratio of 3.05 over our sample period, compared to a Sharpe ratio of 1.23 for the strategy based on the dictionary model. This study highlights the superior performance of LLMs in financial sentiment analysis, encouraging further research into integrating artificial intelligence and LLMs in financial markets.", "citations": 9}
{"title": "Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning", "year": 2025, "authors": "Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua", "url": "https://www.semanticscholar.org/paper/edce9c10e3932d2d2d138a0523bb3e8a6bbe1b6b", "relevance": 1, "abstract": "Signal decay and regime shifts pose recurring challenges for data-driven investment strategies in non-stationary markets. Conventional time-series and machine learning approaches, which rely primarily on historical correlations, often struggle to generalize when the economic environment changes. While large language models (LLMs) offer strong capabilities for processing unstructured information, their potential to support quantitative factor screening through explicit economic reasoning remains underexplored. Existing factor-based methods typically reduce alphas to numerical time series, overlooking the semantic rationale that determines when a factor is economically relevant. We propose Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. Alpha-R1 reasons over factor logic and real-time news to evaluate alpha relevance under changing market conditions, selectively activating or deactivating factors based on contextual consistency. Empirical results across multiple asset pools show that Alpha-R1 consistently outperforms benchmark strategies and exhibits improved robustness to alpha decay. The full implementation and resources are available at https://github.com/FinStep-AI/Alpha-R1.", "citations": 0}
{"title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review", "year": 2025, "authors": "M. Ferrag, Norbert Tihanyi, M. Debbah", "url": "https://www.semanticscholar.org/paper/6758a6db1bfb6ebc5134aea9ce0fc28dd2e031a4", "relevance": 1, "abstract": "Large language models and autonomous AI agents have evolved rapidly, resulting in a diverse array of evaluation benchmarks, frameworks, and collaboration protocols. However, the landscape remains fragmented and lacks a unified taxonomy or comprehensive survey. Therefore, we present a side-by-side comparison of benchmarks developed between 2019 and 2025 that evaluate these models and agents across multiple domains. In addition, we propose a taxonomy of approximately 60 benchmarks that cover general and academic knowledge reasoning, mathematical problem-solving, code generation and software engineering, factual grounding and retrieval, domain-specific evaluations, multimodal and embodied tasks, task orchestration, and interactive assessments. Furthermore, we review AI-agent frameworks introduced between 2023 and 2025 that integrate large language models with modular toolkits to enable autonomous decision-making and multi-step reasoning. Moreover, we present real-world applications of autonomous AI agents in materials science, biomedical research, academic ideation, software engineering, synthetic data generation, chemical reasoning, mathematical problem-solving, geographic information systems, multimedia, healthcare, and finance. We then survey key agent-to-agent collaboration protocols, namely the Agent Communication Protocol (ACP), the Model Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally, we discuss recommendations for future research, focusing on advanced reasoning strategies, failure modes in multi-agent LLM systems, automated scientific discovery, dynamic tool integration via reinforcement learning, integrated search capabilities, and security vulnerabilities in agent protocols.", "citations": 94}
{"title": "PriceSeer: Evaluating Large Language Models in Real-Time Stock Prediction", "year": 2025, "authors": "Bohan Liang, Zijian Chen, Qi Jia, Kaiwei Zhang, Kaiyuan Ji, Guangtao Zhai", "url": "https://www.semanticscholar.org/paper/baf62e648a717c636b2fd5c2b12dec500191327f", "relevance": 1, "abstract": "Stock prediction, a subject closely related to people's investment activities in fully dynamic and live environments, has been widely studied. Current large language models (LLMs) have shown remarkable potential in various domains, exhibiting expert-level performance through advanced reasoning and contextual understanding. In this paper, we introduce PriceSeer, a live, dynamic, and data-uncontaminated benchmark specifically designed for LLMs performing stock prediction tasks. Specifically, PriceSeer includes 110 U.S. stocks from 11 industrial sectors, with each containing 249 historical data points. Our benchmark implements both internal and external information expansion, where LLMs receive extra financial indicators, news, and fake news to perform stock price prediction. We evaluate six cutting-edge LLMs under different prediction horizons, demonstrating their potential in generating investment strategies after obtaining accurate price predictions for different sectors. Additionally, we provide analyses of LLMs'suboptimal performance in long-term predictions, including the vulnerability to fake news and specific industries. The code and evaluation data will be open-sourced at https://github.com/BobLiang2113/PriceSeer.", "citations": 0}
{"title": "FinRL: Adaptive Model Selection for Reinforcement Learning in Stock Trading", "year": 2025, "authors": "Vorakorn Kosidphokin, Phawat Loedtrakunchai, Natthakorn Sinamnuaiphon, Surawit Kuptanon", "url": "https://www.semanticscholar.org/paper/776e96194a39cd687c66b3e4d0bf8df9810f64aa", "relevance": 1, "abstract": "This paper advances the FinRL-DeepSeek framework by introducing a market-adaptive modeling approach to improve automated stock trading agents. While FinRL-DeepSeek integrates stock prices and financial news using reinforcement learning (RL) and large language models (LLMs), our approach incorporates a dynamic model selection mechanism that adapts to market conditions, such as bull and bear markets determined using Nasdaq index trends. We also replace the single-model structure of FinRL-DeepSeek with multiple specialized models, each tailored to individual stocks. This adaptation enables more precise decision making, improving responsiveness to market fluctuations and enhancing overall trading performance.", "citations": 1}
{"title": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models", "year": 2023, "authors": "Alejandro Lopez-Lira, Yuehua Tang", "url": "https://www.semanticscholar.org/paper/d26c55bee1ac6856a20862b0f7b4ff38fa39af50", "relevance": 1, "abstract": "We document the capability of large language models (LLMs) like ChatGPT to predict stock market reactions from news headlines without direct financial training. Using post-knowledge-cutoff headlines, GPT-4 captures initial market responses, achieving approximately 90% portfolio-day hit rates for the non-tradable initial reaction. GPT-4 scores also significantly predict the subsequent drift, especially for small stocks and negative news. Forecasting ability generally increases with model size, suggesting that financial reasoning is an emerging capacity of complex LLMs. Strategy returns decline as LLM adoption rises, consistent with improved price efficiency. To rationalize these findings, we develop a theoretical model that incorporates LLM technology, information-processing capacity constraints, underreaction, and limits to arbitrage.", "citations": 266}
{"title": "FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models", "year": 2024, "authors": "Hongyang Yang, Boyu Zhang, Neng Wang, Cheng Guo, Xiaoli Zhang, Likun Lin, Junlin Wang, Tianyu Zhou, Mao Guan, Runjia Zhang, Chris Wang", "url": "https://www.semanticscholar.org/paper/780881ba7440fb95ebc7114d8f219466275102f8", "relevance": 1, "abstract": "As financial institutions and professionals increasingly incorporate Large Language Models (LLMs) into their workflows, substantial barriers, including proprietary data and specialized knowledge, persist between the finance sector and the AI community. These challenges impede the AI community's ability to enhance financial tasks effectively. Acknowledging financial analysis's critical role, we aim to devise financial-specialized LLM-based toolchains and democratize access to them through open-source initiatives, promoting wider AI adoption in financial decision-making. In this paper, we introduce FinRobot, a novel open-source AI agent platform supporting multiple financially specialized AI agents, each powered by LLM. Specifically, the platform consists of four major layers: 1) the Financial AI Agents layer that formulates Financial Chain-of-Thought (CoT) by breaking sophisticated financial problems down into logical sequences; 2) the Financial LLM Algorithms layer dynamically configures appropriate model application strategies for specific tasks; 3) the LLMOps and DataOps layer produces accurate models by applying training/fine-tuning techniques and using task-relevant data; 4) the Multi-source LLM Foundation Models layer that integrates various LLMs and enables the above layers to access them directly. Finally, FinRobot provides hands-on for both professional-grade analysts and laypersons to utilize powerful AI techniques for advanced financial analysis. We open-source FinRobot at \\url{https://github.com/AI4Finance-Foundation/FinRobot}.", "citations": 32}
{"title": "StockSim: A Dual-Mode Order-Level Simulator for Evaluating Multi-Agent LLMs in Financial Markets", "year": 2025, "authors": "Charidimos Papadakis, Giorgos Filandrianos, Angeliki Dimitriou, Maria Lymperaiou, Konstantinos Thomas, G. Stamou", "url": "https://www.semanticscholar.org/paper/336c89f0dadae33e79c1730e2f62f78ad4c3fffe", "relevance": 1, "abstract": "We present StockSim, an open-source simulation platform for systematic evaluation of large language models (LLMs) in realistic financial decision-making scenarios. Unlike previous toolkits that offer limited scope, StockSim delivers a comprehensive system that fully models market dynamics and supports diverse simulation modes of varying granularity. It incorporates critical real-world factors, such as latency, slippage, and order-book microstructure, that were previously neglected, enabling more faithful and insightful assessment of LLM-based trading agents. An extensible, role-based agent framework supports heterogeneous trading strategies and multi-agent coordination, making StockSim a uniquely capable testbed for NLP research on reasoning under uncertainty and sequential decision-making. We open-source all our code at https: //github.com/harrypapa2002/StockSim.", "citations": 4}
{"title": "Standard Benchmarks Fail -- Auditing LLM Agents in Finance Must Prioritize Risk", "year": 2025, "authors": "Zichen Chen, Jiaao Chen, Jianda Chen, Misha Sra", "url": "https://www.semanticscholar.org/paper/e06f72ec485c85472d1380d5667adb417635c981", "relevance": 1, "abstract": "Standard benchmarks fixate on how well large language model (LLM) agents perform in finance, yet say little about whether they are safe to deploy. We argue that accuracy metrics and return-based scores provide an illusion of reliability, overlooking vulnerabilities such as hallucinated facts, stale data, and adversarial prompt manipulation. We take a firm position: financial LLM agents should be evaluated first and foremost on their risk profile, not on their point-estimate performance. Drawing on risk-engineering principles, we outline a three-level agenda: model, workflow, and system, for stress-testing LLM agents under realistic failure modes. To illustrate why this shift is urgent, we audit six API-based and open-weights LLM agents on three high-impact tasks and uncover hidden weaknesses that conventional benchmarks miss. We conclude with actionable recommendations for researchers, practitioners, and regulators: audit risk-aware metrics in future studies, publish stress scenarios alongside datasets, and treat ``safety budget'' as a primary success criterion. Only by redefining what ``good'' looks like can the community responsibly advance AI-driven finance.", "citations": 5}
{"title": "Multimodal Financial Foundation Models (MFFMs): Progress, Prospects, and Challenges", "year": 2025, "authors": "Xiao-Yang Liu Yanglet, Yupeng Cao, Li Deng", "url": "https://www.semanticscholar.org/paper/290fe5dfb5d33902c9311aaead75201747acc4d8", "relevance": 1, "abstract": "Financial Large Language Models (FinLLMs), such as open FinGPT and proprietary BloombergGPT, have demonstrated great potential in select areas of financial services. Beyond this earlier language-centric approach, Multimodal Financial Foundation Models (MFFMs) can digest interleaved multimodal financial data, including fundamental data, market data, data analytics, macroeconomic, and alternative data (e.g., natural language, audio, images, and video). In this position paper, presented at the MFFM Workshop joined with ACM International Conference on AI in Finance (ICAIF) 2024, we describe the progress, prospects, and challenges of MFFMs. This paper also highlights ongoing research on FinAgents in the \\textbf{SecureFinAI Lab}\\footnote{\\https://openfin.engineering.columbia.edu/} at Columbia University. We believe that MFFMs will enable a deeper understanding of the underlying complexity associated with numerous financial tasks and data, streamlining the operation of financial services and investment processes. Github Repo https://github.com/Open-Finance-Lab/Awesome-MFFMs/.", "citations": 4}
{"title": "A Survey on the Optimization of Large Language Model-based Agents", "year": 2025, "authors": "Shangheng Du, Jiabao Zhao, Jinxin Shi, Zhentao Xie, Xin Jiang, Yanhong Bai, Liang He", "url": "https://www.semanticscholar.org/paper/2ec6caff88519e06a3148fe2890f1741b30ce623", "relevance": 1, "abstract": "With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks. However, current work typically relies on prompt design or fine-tuning strategies applied to vanilla LLMs, which often leads to limited effectiveness in complex agent-related environments. Although numerous recent studies have explored various strategies to optimize LLM-based agents for complex agent tasks, a systematic review summarizing and comparing these methods from a holistic perspective remains lacking. In this survey, we provide a comprehensive review of LLM-based agent optimization approaches, categorizing them into parameter-driven and parameter-free methods. We first focus on parameter-driven optimization, covering fine-tuning-based optimization, reinforcement learning-based optimization, and hybrid strategies, analyzing key aspects such as trajectory data construction, reward function design, and optimization algorithms. Additionally, we briefly discuss parameter-free strategies that optimize agent behavior through prompt engineering and external knowledge retrieval. Finally, we summarize the evaluation for agents, review key applications of LLM-based agents, and discuss the major challenges and promising future directions. A curated collection of the surveyed works is provided at https://github.com/YoungDubbyDu/LLM-Agent-Optimization.", "citations": 21}
{"title": "What Teaches Robots to Walk, Teaches Them to Trade too - Regime Adaptive Execution using Informed Data and LLMs", "year": 2024, "authors": "Raeid Saqur", "url": "https://api.semanticscholar.org/CorpusId:270703762", "relevance": 1, "abstract": "Machine learning techniques applied to the problem of financial market forecasting struggle with dynamic regime switching, or underlying correlation and covariance shifts in true (hidden) market variables. Drawing inspiration from the success of reinforcement learning in robotics, particularly in agile locomotion adaptation of quadruped robots to unseen terrains, we introduce an innovative approach that leverages world knowledge of pretrained LLMs (aka. 'privileged information' in robotics) and dynamically adapts them using intrinsic, natural market rewards using LLM alignment technique we dub as\"Reinforcement Learning from Market Feedback\"(**RLMF**). Strong empirical results demonstrate the efficacy of our method in adapting to regime shifts in financial markets, a challenge that has long plagued predictive models in this domain. The proposed algorithmic framework outperforms best-performing SOTA LLM models on the existing (FLARE) benchmark stock-movement (SM) tasks by more than 15\\% improved accuracy. On the recently proposed NIFTY SM task, our adaptive policy outperforms the SOTA best performing trillion parameter models like GPT-4. The paper details the dual-phase, teacher-student architecture and implementation of our model, the empirical results obtained, and an analysis of the role of language embeddings in terms of Information Gain.", "citations": 3}
{"title": "Bridging Language Models and Financial Analysis", "year": 2025, "authors": "Alejandro Lopez-Lira, Jihoon Kwon, Sangwoong Yoon, Jy-yong Sohn, Chanyeol Choi", "url": "https://www.semanticscholar.org/paper/0f5978f91ea75524fa2bb20af5cdb34709b9771f", "relevance": 1, "abstract": "The rapid advancements in Large Language Models (LLMs) have unlocked transformative possibilities in natural language processing, particularly within the financial sector. Financial data is often embedded in intricate relationships across textual content, numerical tables, and visual charts, posing challenges that traditional methods struggle to address effectively. However, the emergence of LLMs offers new pathways for processing and analyzing this multifaceted data with increased efficiency and insight. Despite the fast pace of innovation in LLM research, there remains a significant gap in their practical adoption within the finance industry, where cautious integration and long-term validation are prioritized. This disparity has led to a slower implementation of emerging LLM techniques, despite their immense potential in financial applications. As a result, many of the latest advancements in LLM technology remain underexplored or not fully utilized in this domain. This survey seeks to bridge this gap by providing a comprehensive overview of recent developments in LLM research and examining their applicability to the financial sector. Building on previous survey literature, we highlight several novel LLM methodologies, exploring their distinctive capabilities and their potential relevance to financial data analysis. By synthesizing insights from a broad range of studies, this paper aims to serve as a valuable resource for researchers and practitioners, offering direction on promising research avenues and outlining future opportunities for advancing LLM applications in finance.", "citations": 5}
{"title": "LLM-Augmented Linear Transformer\u2013CNN for Enhanced Stock Price Prediction", "year": 2025, "authors": "Lei Zhou, Yuqi Zhang, Jian Yu, Guiling Wang, Zhizhong Liu, Sira Yongchareon, Nancy Wang", "url": "https://www.semanticscholar.org/paper/0133a1bcf4594ffc12e21fc01464258e818f1332", "relevance": 1, "abstract": "Accurately predicting stock prices remains a challenging task due to the volatile and complex nature of financial markets. In this study, we propose a novel hybrid deep learning framework that integrates a large language model (LLM), a Linear Transformer (LT), and a Convolutional Neural Network (CNN) to enhance stock price prediction using solely historical market data. The framework leverages the LLM as a professional financial analyst to perform daily technical analysis. The technical indicators, including moving averages (MAs), relative strength index (RSI), and Bollinger Bands (BBs), are calculated directly from historical stock data. These indicators are then analyzed by the LLM, generating descriptive textual summaries. The textual summaries are further transformed into vector representations using FinBERT, a pre-trained financial language model, to enhance the dataset with contextual insights. The FinBERT embeddings are integrated with features from two additional branches: the Linear Transformer branch, which captures long-term dependencies in time-series stock data through a linearized self-attention mechanism, and the CNN branch, which extracts spatial features from visual representations of stock chart data. The combined features from these three modalities are then processed by a Feedforward Neural Network (FNN) for final stock price prediction. Experimental results on the S&P 500 dataset demonstrate that the proposed framework significantly improves stock prediction accuracy by effectively capturing temporal, spatial, and contextual dependencies in the data. This multimodal approach highlights the importance of integrating advanced technical analysis with deep learning architectures for enhanced financial forecasting.", "citations": 19}
{"title": "ABIDES-MARL: A Multi-Agent Reinforcement Learning Environment for Endogenous Price Formation and Execution in a Limit Order Book", "year": 2025, "authors": "Patrick Cheridito, Jean-Loup Dupret, Zhexin Wu", "url": "https://www.semanticscholar.org/paper/367a48ee51e9a33975fa0cd5584baa21e7bd70be", "relevance": 1, "abstract": "We present ABIDES-MARL, a framework that combines a new multi-agent reinforcement learning (MARL) methodology with a new realistic limit-order-book (LOB) simulation system to study equilibrium behavior in complex financial market games. The system extends ABIDES-Gym by decoupling state collection from kernel interruption, enabling synchronized learning and decision-making for multiple adaptive agents while maintaining compatibility with standard RL libraries. It preserves key market features such as price-time priority and discrete tick sizes. Methodologically, we use MARL to approximate equilibrium-like behavior in multi-period trading games with a finite number of heterogeneous agents-an informed trader, a liquidity trader, noise traders, and competing market makers-all with individual price impacts. This setting bridges optimal execution and market microstructure by embedding the liquidity trader's optimization problem within a strategic trading environment. We validate the approach by solving an extended Kyle model within the simulation system, recovering the gradual price discovery phenomenon. We then extend the analysis to a liquidity trader's problem where market liquidity arises endogenously and show that, at equilibrium, execution strategies shape market-maker behavior and price dynamics. ABIDES-MARL provides a reproducible foundation for analyzing equilibrium and strategic adaptation in realistic markets and contributes toward building economically interpretable agentic AI systems for finance.", "citations": 1}
{"title": "Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review", "year": 2025, "authors": "Anjana Sarkar, Soumyendu Sarkar", "url": "https://api.semanticscholar.org/CorpusId:279244795", "relevance": 1, "abstract": "This survey investigates how classical software design patterns can enhance the reliability and scalability of communication in Large Language Model (LLM)-driven agentic AI systems, focusing particularly on the Model Context Protocol (MCP). It examines the foundational architectures of LLM-based agents and their evolution from isolated operation to sophisticated, multi-agent collaboration, addressing key communication hurdles that arise in this transition. The study revisits well-established patterns, including Mediator, Observer, Publish-Subscribe, and Broker, and analyzes their relevance in structuring agent interactions within MCP-compliant frameworks. To clarify these dynamics, the article provides conceptual schematics and formal models that map out communication pathways and optimize data flow. It further explores architectural variations suited to different degrees of agent autonomy and system complexity. Real-world applications in domains such as real-time financial processing and investment banking are discussed, illustrating how these patterns and MCP can meet specific operational demands. The article concludes by outlining open challenges, potential security risks, and promising directions for advancing robust, interoperable, and scalable multi-agent LLM ecosystems.", "citations": 10}
{"title": "FinVerse: An Autonomous Agent System for Versatile Financial Analysis", "year": 2024, "authors": "Siyu An, Qin Li, Junru Lu, Di Yin, Xing Sun", "url": "https://www.semanticscholar.org/paper/aa0073abec030acabb1051cbf26c568df537ddae", "relevance": 1, "abstract": "With the significant advancements in cognitive intelligence driven by LLMs, autonomous agent systems have attracted extensive attention. Despite this growing interest, the development of stable and efficient agent systems poses substantial practical challenges. In this paper, we introduce FinVerse, a meticulously crafted agent system designed for a broad range of financial topics. FinVerse integrates over 600 financial APIs, enabling access to more accurate and extensive financial information compared to generalist agents. To enhance financial information processing capabilities, FinVerse is equipped with an embedded code interpreter, enabling the execution of complex data analysis tasks with precision and efficiency. Our work includes an empirical comparison of several LLMs in driving FinVerse. Specifically, we propose our own scheme for training LLMs using SFT to optimize LLM performance within FinVerse. Recognizing the scarcity of specialized datasets to build LLMs for agents, we have constructed a dataset and plan to make it open-source, providing a valuable resource for peer application developers. The demo video has been released on YouTube at https://www.youtube.com/watch?v=sk8L9_Wv7J4", "citations": 10}
{"title": "Parallel Market Environments for FinRL Contests", "year": 2025, "authors": "Keyi Wang, Kairong Xiao, Xiao-Yang Liu Yanglet", "url": "https://www.semanticscholar.org/paper/388ecbb98f3705b390b8b2ac816f8a42a88fa656", "relevance": 1, "abstract": "Financial reinforcement learning has attracted lots of attention recently. From 2023 to 2025, we have organized three FinRL Contests featuring different financial tasks. Large language models have a strong capability to process financial documents. By integrating LLM-generated signals into the state, trading agents can take smarter actions based on both structured market data and unstructured financial documents. In this paper, we summarize the parallel market environments for tasks used in FinRL Contests 2023-2025. To address the sampling bottleneck during training, we introduce GPU-optimized parallel market environments to address the sampling bottleneck. In particular, two new tasks incorporate LLM-generated signals and all tasks support massively parallel simulation. Contestants have used these market environments to train robust and powerful trading agents for both stock and cryptocurrency trading tasks.", "citations": 6}
{"title": "FinRL Contests: Data\u2010Driven Financial Reinforcement Learning Agents for Stock and Crypto Trading", "year": 2025, "authors": "Keyi Wang, Nikolaus Holzer, Ziyi Xia, Yupeng Cao, Jiechao Gao, Anwar Walid, Kairong Xiao, Xiao-Yang Liu Yanglet", "url": "https://www.semanticscholar.org/paper/f2af5174daaeac47d02ad672220bc4ab8b7c9b2b", "relevance": 1, "abstract": "Financial reinforcement learning (FinRL) is now a practical paradigm for financial engineering. However, applying RL strategies to real\u2010world trading tasks remains a challenge for individuals, as it is error\u2010prone and engineering\u2010heavy. The stock and crypto trading tasks pose unique challenges due to the non\u2010stationarity of financial data, low signal\u2010to\u2010noise ratios and various market frictions. Although numerous FinRL methods have been developed for stock and crypto trading tasks, the lack of standardised task definitions, real\u2010time high\u2010quality datasets, close\u2010to\u2010real market environments and robust baselines has hindered consistent reproduction in both the open\u2010source community and the FinTech industry. To bridge this gap, we organised a series of FinRL Contests from 2023 to 2025, covering a diverse range of financial tasks such as stock trading, order execution, crypto trading, and the use of large language model (LLM)\u2010engineered signals. These contests attracted 230+ participants from 100+ institutions in 20+ countries. To encourage participation, we provided starter kits that feature GPU\u2010optimised parallel market environments, ensemble learning methods, and comprehensive instructions. In this paper, we summarise these benchmarking efforts, detailing trading task formulations, data curation pipelines, environment implementations, evaluation protocols, participant performance and organisational insights. It guides our follow\u2010up FinRL Contests and also provides a reference pipeline for FinAI contests alike.", "citations": 2}
{"title": "Stock Price Trend Prediction using Emotion Analysis of Financial Headlines with Distilled LLM Model", "year": 2024, "authors": "Rithesh Bhat, Bhanu Jain", "url": "https://www.semanticscholar.org/paper/d57bda730ec5751b95d62b7ca92fd68a0336edc4", "relevance": 1, "abstract": "Capturing the volatility of stock prices helps individual traders, stock analysts, and institutions alike increase their returns in the stock market. Financial news headlines have been shown to have a significant effect on stock price mobility. Lately, many financial portals have restricted web scraping of stock prices and other related financial data of companies from their websites. In this study we demonstrate that emotion analysis of financial news headlines alone can be sufficient in predicting stock price movement, even in the absence of any financial data. We propose an approach that eliminates the need for web scraping of financial data. We use API based mechanism to retrieve financial news headlines. In this study we train and subsequently leverage light and computationally fast Distilled LLM Model to gather emotional tone and strength of financial news headlines for companies. We then use this information with several machine learning-based classification algorithms to predict the stock price direction based solely on the emotion analysis of news. We demonstrate that emotion analysis-based attributes of financial news headlines are as accurate in predicting the price direction as running the algorithms with the financial data alone.", "citations": 20}
{"title": "Inherent and emergent liability issues in LLM-based agentic systems: a principal-agent perspective", "year": 2025, "authors": "Garry Gabison, R. P. Xian, Ck Sq, An Ck Sq", "url": "https://api.semanticscholar.org/CorpusId:277596142", "relevance": 1, "abstract": "Agentic systems powered by large language models (LLMs) are becoming progressively more complex and capable. Their increasing agency and expanding deployment settings attract growing attention to effective governance policies, monitoring, and control protocols. Based on the emerging landscape of the agentic market, we analyze potential liability issues arising from the delegated use of LLM agents and their extended systems through a principal-agent perspective. Our analysis complements existing risk-based studies on artificial agency and covers the spectrum of important aspects of the principal-agent relationship and their potential consequences at deployment. Furthermore, we motivate method developments for technical governance along the directions of interpretability and behavior evaluations, reward and conflict management, and the mitigation of misalignment and misconduct through principled engineering of detection and fail-safe mechanisms. By illustrating the outstanding issues in AI liability for LLM-based agentic systems, we aim to inform the system design, auditing, and tracing to enhance transparency and liability attribution.", "citations": 11}
